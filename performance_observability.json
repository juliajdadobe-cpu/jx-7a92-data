{
  "Производительность / Observability": [
    {
      "question": "Что такое мониторинг и observability в микросервисах? Какие метрики/инструменты использовать (например, Spring Boot Actuator, Prometheus/Grafana, CloudWatch)?",
      "answer": "Мониторинг — это про «что сломалось?» (метрики/алерты по заранее известным сигналам).\n\nObservability (наблюдаемость) — это про «почему и где сломалось?», даже если проблема новая. Обычно опирается на три столпа: метрики, логи, трейсы.\n\nИнструменты:\n- Spring Boot Actuator + Micrometer (метрики),\n- Prometheus (сбор) + Grafana (дашборды/алерты),\n- логи: ELK/EFK, Loki,\n- tracing: OpenTelemetry + Jaeger/Zipkin,\n- облако: CloudWatch, Stackdriver и т.п."
    },
    {
      "question": "Ваш сервис стал медленным. На что смотреть и как локализовать узкие места?",
      "answer": "План диагностики:\n- проверить метрики: p95/p99 latency, error rate, RPS, saturation (CPU, память, GC, threads, pool’ы).\n- посмотреть зависимости: БД, внешние сервисы, очереди (latency/ошибки).\n- посмотреть трейсы: где именно тратится время (DB, HTTP, сериализация, бизнес-логика).\n- проверить блокировки/очереди: thread dumps, connection pool, queue length.\n\nГлавная цель — найти «узкое место»: CPU, I/O (БД/сеть), блокировки или лимиты ресурсов."
    },
    {
      "question": "Внешний сервис стал медленным: как это выявить и чем защититься (timeouts, retries, fallback, circuit breaker)?",
      "answer": "Выявить:\n- метрики по исходящим вызовам (latency/error rate по endpoint’ам),\n- distributed tracing (спаны внешнего вызова),\n- логи с correlation id.\n\nЗащита:\n- таймауты (connect/read),\n- ретраи только для безопасных ошибок + backoff + лимит (иначе усилите проблему),\n- fallback/деградация (кэш, заглушка),\n- circuit breaker (Resilience4j) + bulkhead (изоляция ресурсов).\n\nЦель — чтобы «медленная зависимость» не утащила ваш сервис."
    },
    {
      "question": "Как выстроить наблюдаемость так, чтобы команда узнавала о проблемах раньше менеджера/пользователей?",
      "answer": "- СЛО/SLA/SLO: определить цели по latency/availability/error rate.\n- Настроить алерты по SLO (например, error budget burn rate), а не только по CPU.\n- Централизованные логи + трассировка с `traceId`.\n- Дашборды по ключевым сервисам и зависимостям.\n- Авто-алерты по аномалиям (рост p99, рост лагов, рост ошибок).\n\nИ главное: алерты должны быть «действуемыми» (понятно, что делать)."
    },
    {
      "question": "Как действовать при релизе: что мониторить после выката?",
      "answer": "После релиза смотрят:\n- error rate (5xx/исключения),\n- latency (p95/p99),\n- RPS и успешность запросов,\n- метрики БД/очередей (pool, lag),\n- ресурсы (CPU/memory/GC/threads),\n- бизнес-метрики (заказы/оплаты).\n\nЕсли есть canary/blue-green — сравнивают новую версию со старой. Важно иметь быстрый rollback/rollforward."
    },
    {
      "question": "Как залогировать время выполнения с привязкой к конкретному пользователю, пришедшему в аргументах метода?",
      "answer": "Подход:\n- добавить correlation id (`traceId`/`requestId`) в MDC,\n- получить userId (из SecurityContext или аргумента),\n- логировать `userId`, `traceId`, имя операции и duration.\n\nРеализация:\n- AOP `@Around` аспект для методов сервиса,\n- или фильтр/интерсептор на уровне web.\n\nВажно не логировать чувствительные данные и не раздувать логи."
    },
    {
      "question": "Как подойти к профилированию задержек (latency) в сервисе?",
      "answer": "Шаги:\n- начать с метрик p95/p99 и распределения латентности.\n- включить трассировку (OpenTelemetry) и посмотреть, где время: БД, внешние HTTP, сериализация, бизнес-код.\n- для CPU-bound: снять CPU профайл.\n- для I/O: проверить пул соединений, таймауты, очереди.\n\nГлавное — измерять на прод-похожей нагрузке и подтверждать улучшения метриками."
    },
    {
      "question": "Как понять, как живёт сервис в проде: какие метрики/логи смотреть, какими инструментами?",
      "answer": "Смотреть:\n- RED/USE: Request rate, Errors, Duration; Utilization, Saturation.\n- JVM: heap, GC pauses, threads, CPU.\n- Пулы: DB connection pool, thread pools.\n- Зависимости: latency/ошибки внешних сервисов.\n\nИнструменты:\n- Actuator/Micrometer → Prometheus/Grafana,\n- логи → ELK/Loki,\n- трейсы → OpenTelemetry + Jaeger/Zipkin,\n- профилирование → async-profiler/YourKit."
    },
    {
      "question": "Какие метрики и алерты вы бы настроили в графане/прометеусе для микросервисов?",
      "answer": "База:\n- latency p95/p99 по endpoint’ам,\n- error rate (5xx, exceptions),\n- RPS,\n- saturation: CPU, memory, GC, threads,\n- DB: pool usage, slow queries, timeouts,\n- очередь/стрим: lag, retries, DLQ.\n\nАлерты:\n- по SLO (burn rate),\n- резкий рост p99,\n- рост 5xx,\n- истощение пулов,\n- рост lag/DLQ."
    },
    {
      "question": "Какие метрики и health-чеки должны быть у Spring-сервиса?",
      "answer": "Health-check:\n- liveness (жив ли процесс),\n- readiness (готов принимать трафик: БД/очереди доступны).\n\nВ Spring это обычно через Actuator: `/actuator/health/liveness`, `/actuator/health/readiness`.\n\nМетрики:\n- HTTP latency/error/RPS,\n- JVM (heap/GC/threads),\n- pool’ы (Tomcat threads, DB connections),\n- кастомные бизнес-метрики."
    },
    {
      "question": "Какие способы профилирования Java-приложений ты знаешь и для каких кейсов их используешь?",
      "answer": "- CPU profiling: async-profiler, YourKit, JProfiler — когда подозрение на CPU-bound узкое место.\n- Heap/allocations: heap dump + MAT, профайлер — когда утечки/большие аллокации.\n- Thread dumps: `jstack`, `jcmd` — когда блокировки/зависания/истощение пулов.\n- GC logs: `-Xlog:gc*` — когда проблемы с GC паузами.\n\nВыбор инструмента зависит от симптома: CPU, память, блокировки, I/O."
    },
    {
      "question": "Медленный endpoint с большим числом операций в БД: как диагностировать и ускорять?",
      "answer": "Диагностика:\n- tracing: сколько времени в БД,\n- лог медленных запросов, `EXPLAIN ANALYZE`,\n- проверить N+1, количество запросов на запрос.\n\nУскорение:\n- индексы и оптимизация запросов,\n- уменьшить число запросов (join fetch, batch, правильные репозитории),\n- кэшировать чтение,\n- батчить записи,\n- ограничить объём данных (пагинация),\n- настроить pool соединений."
    },
    {
      "question": "Пропускная способность: если 500 RPS и обработка 2 сек — сколько потоков нужно? Сколько потоков в Tomcat по умолчанию? Как масштабироваться?",
      "answer": "Грубая оценка по Little’s Law: одновременно в работе ≈ RPS * latency = 500 * 2 = 1000 запросов «в полёте». В блокирующей модели это означает, что для обслуживания без очередей нужен порядок сотен/тысяч потоков, что обычно нереалистично.\n\nTomcat по умолчанию имеет `maxThreads` порядка 200 (зависит от версии/настроек).\n\nКак масштабироваться:\n- уменьшать latency (оптимизация, кэш),\n- использовать асинхронность/неблокирующие подходы для I/O (или виртуальные потоки),\n- горизонтально масштабировать инстансы,\n- ограничивать нагрузку (rate limiting),\n- разделять тяжёлые операции в async пайплайны."
    },
    {
      "question": "Endpoint медленный из-за собственной логики: как искать узкое место (профилирование CPU/heap)? Какие инструменты знаешь?",
      "answer": "Если подозрение на CPU:\n- снять CPU профайл (async-profiler/YourKit/JProfiler),\n- посмотреть hottest methods/lock contention.\n\nЕсли подозрение на память/аллокации:\n- allocation profiling, heap dump (MAT),\n- поиск «горячих» аллокаторов, утечек.\n\nДополнительно: thread dumps (`jstack`), метрики GC (`-Xlog:gc*`). Важно воспроизвести на прод-похожей нагрузке."
    },
    {
      "question": "Использовал ли кэши? Что и зачем хранил в Redis?",
      "answer": "Кэш используют, чтобы снизить latency и нагрузку на БД/внешние сервисы.\n\nВ Redis обычно хранят:\n- результаты частых чтений (например, профили пользователей),\n- сессии/токены (если нужно),\n- rate limiting счётчики,\n- распределённые локи,\n- данные для очередей/стримов,\n- подготовленные агрегаты.\n\nВажно: TTL, инвалидация, стратегия обновления и учёт консистентности."
    },
    {
      "question": "Какую структуру данных выбрать для кэша в многопоточной среде? Как сделать распределённый кэш?",
      "answer": "Локальный кэш в памяти:\n- чаще всего `ConcurrentHashMap` или готовые библиотеки (Caffeine) с TTL/лимитами.\n\nРаспределённый кэш:\n- Redis (через Spring Cache, Redisson и т.п.).\n\nВажно:\n- TTL и политика инвалидирования,\n- защита от stampede (когда много потоков одновременно «пробивает» кэш),\n- сериализация и размер объектов,\n- consistency: понимать, что кэш может быть слегка устаревшим."
    }
  ]
}
