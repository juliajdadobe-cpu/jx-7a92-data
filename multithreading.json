{
  "Многопоточность": [
    {
      "question": "Асинхронность vs многопоточность: в чём разница?",
      "answer": "Асинхронность — это про *неблокирующее* выполнение: мы запускаем операцию и продолжаем делать другие дела, а результат получаем позже (callback/`Future`/`CompletableFuture`). Это можно реализовать даже в одном потоке (event loop).\n\nМногопоточность — это про выполнение кода *в нескольких потоках* одновременно (конкурентно, а иногда и параллельно на разных ядрах).\n\nВажно: асинхронность может быть реализована *через* потоки (например, `CompletableFuture` на пуле), но это не одно и то же."
    },
    {
      "question": "В чём отличие Executors.newFixedThreadPool и Executors.newCachedThreadPool?",
      "answer": "`newFixedThreadPool(n)` — пул с фиксированным числом потоков. Если задач больше, чем потоков, они обычно встают в очередь. Хорошо, когда нужно ограничить параллелизм и нагрузку.\n\n`newCachedThreadPool()` — пул без фиксированного размера: создаёт новые потоки при необходимости и переиспользует простаивающие. Удобен для большого числа коротких задач, но опасен тем, что может создать *слишком много* потоков (перегрев CPU/памяти) при всплесках."
    },
    {
      "question": "В чём проблема подхода с synchronized и какие есть современные альтернативы?",
      "answer": "Проблемы `synchronized`: при конкуренции может сильно падать производительность (контеншен), легко получить дедлоки при неправильном порядке захвата, нет гибких возможностей (таймаут, попытка захвата, несколько условий).\n\nАльтернативы/надстройки:\n- `java.util.concurrent.locks` (`ReentrantLock`, `ReadWriteLock`, `StampedLock`) — больше контроля.\n- атомарные классы (`Atomic*`, `LongAdder`) — для простых атомарных операций без явных блокировок.\n- конкурентные коллекции (`ConcurrentHashMap`, `BlockingQueue`) — готовые безопасные структуры.\n- уменьшение общего состояния: иммутабельность, thread confinement, message passing."
    },
    {
      "question": "В чём проблема synchronized и зачем пакет java.util.concurrent?",
      "answer": "`Synchronized` решает взаимное исключение и видимость, но это низкоуровневый инструмент: им легко «прострелить ногу» (дедлоки, лишняя блокировка, плохая масштабируемость).\n\n`java.util.concurrent` даёт более высокоуровневые и часто более эффективные примитивы: пулы потоков (`ExecutorService`), синхронизаторы (`CountDownLatch`, `Semaphore`), конкурентные коллекции (`ConcurrentHashMap`, `BlockingQueue`), атомики (`Atomic*`) и т.д. Их проще применять правильно и безопасно."
    },
    {
      "question": "В чём разница eager vs lazy singleton и когда какой выбирать?",
      "answer": "Eager singleton — создаётся сразу при загрузке класса. Плюсы: просто и потокобезопасно «само по себе» (инициализация класса гарантируется JVM). Минус: объект создаётся даже если не понадобится.\n\nLazy singleton — создаётся при первом обращении. Плюсы: экономит ресурсы, если объект тяжёлый/может не понадобиться. Минус: в многопоточке нужно обеспечить корректность (например, holder-idiom, `enum`, `synchronized`, double-checked locking с `volatile`)."
    },
    {
      "question": "Где ForkJoinPool уместен, а где использовать не стоит?",
      "answer": "`ForkJoinPool` уместен для CPU-bound задач, которые хорошо делятся на подзадачи (divide-and-conquer): обход дерева, рекурсивные вычисления, параллельные стримы.\n\nНе стоит использовать его для задач, которые *долго блокируются* (I/O, ожидание внешних сервисов): блокирующие операции «съедают» рабочие потоки и могут замедлить/остановить прогресс. Для блокирующего I/O лучше выделить отдельный `ExecutorService` или использовать виртуальные потоки."
    },
    {
      "question": "Два потока вызывают разные synchronized-методы одного объекта — выполнятся ли параллельно?",
      "answer": "Если оба метода `synchronized` и вызваны на *одном и том же экземпляре*, они синхронизируются на одном мониторе (`this`), поэтому параллельно выполняться не будут: второй поток будет ждать освобождения монитора.\n\nПараллельно возможно, если:\n- методы синхронизируются на разных объектах (разные мониторы),\n- вызовы идут на разных экземплярах,\n- один метод `static synchronized` (монитор класса), а другой — обычный `synchronized` (монитор экземпляра)."
    },
    {
      "question": "Для чего нужны пулы потоков и какие их виды знаешь?",
      "answer": "Пулы потоков нужны, чтобы:\n- не создавать/уничтожать потоки на каждую задачу (это дорого),\n- ограничивать параллелизм и нагрузку,\n- управлять жизненным циклом задач (отмена, ожидание, shutdown).\n\nТипы: фиксированный (`fixed`), кэширующий (`cached`), один поток (`single`), планировщик (`scheduled`), `ForkJoinPool`/work-stealing, а также `newVirtualThreadPerTaskExecutor()` для виртуальных потоков."
    },
    {
      "question": "Для чего нужны volatile, synchronized, блокировки и высокоуровневые конкурентные структуры?",
      "answer": "Они решают две ключевые проблемы многопоточности:\n- *видимость* изменений между потоками (кэши/переупорядочивание),\n- *согласованность/атомарность* при доступе к общим данным.\n\n`volatile` даёт видимость и ограничивает переупорядочивание для переменной, но не даёт взаимного исключения.\n\n`synchronized`/`Lock` дают взаимное исключение + гарантии видимости.\n\nВысокоуровневые структуры (`ConcurrentHashMap`, `BlockingQueue`, `Atomic*`, `CountDownLatch` и т.д.) — готовые «безопасные» строительные блоки, обычно предпочтительнее ручной синхронизации."
    },
    {
      "question": "Для чего ReentrantLock и ReadWriteLock?",
      "answer": "`ReentrantLock` — альтернатива `synchronized` с дополнительными возможностями: `tryLock()` (в т.ч. с таймаутом), прерываемое ожидание (`lockInterruptibly()`), справедливость (fair lock), несколько `Condition`.\n\n`ReadWriteLock` (обычно `ReentrantReadWriteLock`) позволяет параллельные чтения и эксклюзивную запись. Полезно, когда чтений много, а записей мало."
    },
    {
      "question": "Для чего volatile и чего оно не гарантирует?",
      "answer": "`volatile` гарантирует, что чтения/записи переменной будут видимы между потоками, и задаёт порядок: запись в `volatile` happens-before последующее чтение этой `volatile`.\n\nНо `volatile` *не гарантирует атомарность составных операций* (например, `x++`, проверка-then-act), не даёт взаимного исключения и не защищает инварианты из нескольких переменных."
    },
    {
      "question": "Если только читаем/пишем переменную без инкремента — что использовать для гарантий видимости?",
      "answer": "Если нужна только видимость «последнего значения» и нет составных операций, обычно достаточно `volatile`.\n\nЕсли значение — ссылка на объект, часто используют паттерн: `volatile` ссылка на *иммутабельный* объект (или новый снапшот) — это даёт простую и быструю публикацию.\n\nЕсли нужно атомарно обновлять значение на основе предыдущего — тогда уже `Atomic*` или блокировки."
    },
    {
      "question": "Зачем знать про synchronized, если современные сервисы почти ничего не хранят в памяти?",
      "answer": "Даже «статeless» сервис всё равно имеет конкуренцию: пулы потоков, очереди, кэши, счётчики метрик, соединения, коллекции в памяти, ленивые инициализации.\n\nЗнание `synchronized` важно, чтобы понимать базовую модель: что такое монитор, взаимное исключение и видимость, как возникают дедлоки и гонки. А уже затем осознанно выбирать более высокоуровневые инструменты."
    },
    {
      "question": "Зачем нужен ExecutorService и когда выбирать newFixedThreadPool vs newCachedThreadPool vs newSingleThreadExecutor?",
      "answer": "`ExecutorService` отделяет «что сделать» (задача) от «где и как выполнить» (пул). Даёт контроль: очередь задач, `Future`, отмена, shutdown.\n\nВыбор:\n- `newFixedThreadPool(n)` — ограничить параллелизм (CPU/DB/внешние ресурсы), предсказуемая нагрузка.\n- `newCachedThreadPool()` — много коротких задач и непредсказуемые пики, но нужно помнить, что пул может разрастись (риск перегруза).\n- `newSingleThreadExecutor()` — строгая последовательность выполнения, удобен для «однопоточного» обработчика/писателя."
    },
    {
      "question": "Зачем нужен ExecutorService?",
      "answer": "`ExecutorService` нужен для управления асинхронными задачами: отправлять задачи на выполнение (`submit/execute`), получать результат через `Future`, отменять задачи, корректно завершать пул (`shutdown`, `awaitTermination`).\n\nГлавная идея — переиспользование потоков и контроль параллелизма вместо создания «голых» `Thread` под каждую работу."
    },
    {
      "question": "Зачем нужны атомарные типы (AtomicInteger, AtomicBoolean и т. п.)?",
      "answer": "Атомарные типы позволяют выполнять операции над значением *атомарно* без явных блокировок (обычно через CAS — compare-and-swap). Это удобно для счётчиков, флагов, ссылок на состояние.\n\nПлюсы: меньше риска дедлоков, часто лучше масштабирование при небольших критических секциях.\nМинусы: при сильном контеншене CAS-циклы тоже могут «жечь» CPU — тогда полезны `LongAdder`/`LongAccumulator`."
    },
    {
      "question": "Зачем нужны тред-пулы, виртуальные потоки и CompletableFuture, почему “голых” Thread недостаточно?",
      "answer": "«Голые» `Thread` дорогие: создание/память/переключения контекста. Если создавать поток на каждую задачу, можно легко перегрузить JVM и ОС.\n\nТред-пулы переиспользуют потоки и позволяют ограничить параллелизм.\n\nВиртуальные потоки (Loom) делают модель «одна задача — один поток» намного дешевле, особенно для блокирующего I/O, но всё равно нужно ограничивать внешние ресурсы (DB, HTTP, файловые дескрипторы).\n\n`CompletableFuture` помогает строить асинхронные цепочки и композицию задач (в т.ч. без блокирующих `get`)."
    },
    {
      "question": "Зачем нужны synchronized, volatile, Lock? Какую проблему они решают?",
      "answer": "Они решают проблему конкурентного доступа к общим данным:\n- без синхронизации возможны гонки (race condition) и «невидимость» обновлений,\n- из-за переупорядочивания и кэшей потоки могут видеть устаревшее состояние.\n\n`synchronized`/`Lock` дают взаимное исключение и гарантии видимости.\n`volatile` даёт видимость/порядок для одной переменной, но не заменяет блокировки для составных операций."
    },
    {
      "question": "Как в CompletableFuture обрабатываются исключения? Как работает exceptionally?",
      "answer": "В `CompletableFuture` исключение «течёт» по цепочке: если этап завершился с ошибкой, последующие этапы по умолчанию тоже будут завершены с ошибкой.\n\nОсновные способы обработать:\n- `exceptionally(fn)` — превращает ошибку в *значение по умолчанию*.\n- `handle((value, ex) -> ...)` — получает и значение, и исключение, можно решить, что вернуть.\n- `whenComplete((value, ex) -> ...)` — для сайд-эффектов (логирование), не меняет результат.\n\n`join()` кидает `CompletionException`, а `get()` — `ExecutionException` (обёртки над причиной)."
    },
    {
      "question": "Как выбираете размер пула потоков (executor)? На что ориентируетесь?",
      "answer": "Ориентир — тип задач:\n- CPU-bound: обычно близко к числу ядер (`Runtime.getRuntime().availableProcessors()`), иногда чуть больше.\n- I/O-bound: потоков может быть больше, потому что часть времени они ждут (сеть/диск/БД).\n\nПрактика: измерения и лимиты. Важно учитывать внешние ресурсы (например, максимум соединений к БД) и избегать безразмерных очередей/пулов."
    },
    {
      "question": "Как дождаться завершения других потоков (Thread.join, CountDownLatch, CyclicBarrier)?",
      "answer": "- `Thread.join()` — ждём конкретный поток до завершения.\n- `CountDownLatch` — «счётчик» на N событий: потоки делают `countDown()`, ожидающий делает `await()` (одноразовый).\n- `CyclicBarrier` — барьер: N потоков доходят до точки и ждут друг друга, затем продолжают (многоразовый, по «раундам»).\n\nЕщё часто используют `CompletableFuture.allOf(...)` или `ExecutorService.invokeAll(...)`."
    },
    {
      "question": "Как достигается потокобезопасность в ConcurrentHashMap?",
      "answer": "`ConcurrentHashMap` оптимизирован для конкуренции: чтения в большинстве случаев не блокируются, а обновления синхронизируются на более мелком уровне (не «одним глобальным замком», как `Hashtable`).\n\nВнутри используются сочетание CAS-операций и блокировок на уровне отдельных бакетов/цепочек (lock striping / bin-level locking), поэтому разные ключи часто можно обновлять параллельно.\n\nВажно: `ConcurrentHashMap` не допускает `null`-ключи/значения."
    },
    {
      "question": "Как запустить отправку уведомления асинхронно? Каким образом и в каком пуле потоков?",
      "answer": "Чаще всего — отправить задачу в `ExecutorService` или через `CompletableFuture`:\n- `executor.submit(() -> sendNotification(...))`\n- `CompletableFuture.runAsync(() -> sendNotification(...), executor)`\n\nКлючевой момент — выбрать подходящий пул:\n- для блокирующего I/O (HTTP/SMTP/DB) — отдельный пул (или виртуальные потоки),\n- не грузить `ForkJoinPool.commonPool()` блокирующими вызовами."
    },
    {
      "question": "Как корректно запустить поток (Thread, Runnable)?",
      "answer": "Правильно запускать поток через `start()`, а не через `run()`:\n- `new Thread(runnable).start()`\n\nНа практике чаще используют `ExecutorService`, чтобы не управлять потоками вручную.\n\nЕщё важно: продумать обработку ошибок (например, `UncaughtExceptionHandler`) и корректное завершение (не оставлять «висящие» потоки)."
    },
    {
      "question": "Как определить, какая из параллельных CompletableFuture «упала», и как собрать общий результат/ретраи?",
      "answer": "Обычно используют `CompletableFuture.allOf(...)`, а затем проверяют каждую задачу:\n- у каждой `future` можно вызвать `handle(...)`/`whenComplete(...)` и сохранить ошибку,\n- после `allOf` сделать `join()` по каждой и собрать список результатов/ошибок.\n\nДля «ретраев» часто делают обёртку: `future.handle((v, ex) -> ...)` и при `ex != null` запускать повтор через отдельный `ScheduledExecutorService` (с задержкой и лимитом попыток)."
    },
    {
      "question": "Как получить результат из Callable и чем опасен Future.get()?",
      "answer": "`Callable<T>` отправляют в пул через `submit`, получая `Future<T>`:\n- `Future<T> f = executor.submit(callable)`\n- `T value = f.get()`\n\nОпасность `Future.get()` — он *блокирует* текущий поток. Если вызвать `get()` внутри того же пула, который должен выполнить зависимую задачу, можно получить дедлок/просадку производительности. Лучше использовать `get(timeout, ...)` или `CompletableFuture`-композицию без блокировок."
    },
    {
      "question": "Как предотвратить deadlock? Какие стратегии применяются?",
      "answer": "Основные стратегии:\n- фиксированный порядок захвата нескольких замков (lock ordering) — чтобы не образовывался цикл ожидания,\n- держать замки как можно меньше по времени, не делать под замком I/O,\n- использовать `tryLock()`/таймаут и откат/повтор,\n- по возможности заменить ручные замки на высокоуровневые структуры (очереди, конкурентные коллекции).\n\nДля диагностики — thread dump (`jstack`, профайлеры) показывает циклы ожидания."
    },
    {
      "question": "Как работает ReadWriteLock (чтение параллельно, запись эксклюзивно)?",
      "answer": "`ReadWriteLock` даёт два замка: `readLock` и `writeLock`.\n\nНесколько потоков могут одновременно держать `readLock` (параллельные чтения), но `writeLock` всегда эксклюзивен: пока идёт запись — новые чтения/записи ждут, и наоборот.\n\nПолезно при «много чтений — мало записей», но нужно следить за возможной голодовкой писателя (writer starvation) и выбирать подходящую политику (fairness)."
    },
    {
      "question": "Как работает synchronized метод vs synchronized (obj) блок?",
      "answer": "`synchronized`-метод эквивалентен блоку `synchronized(this)` (для нестатического метода) или `synchronized(SomeClass.class)` (для `static` метода).\n\n`synchronized(obj)` позволяет выбрать *любой* объект как монитор и ограничить область синхронизации только частью кода — это часто лучше для производительности и уменьшает риск дедлоков."
    },
    {
      "question": "Как работает synchronized-блок/метод? Отличия статического/нестатического/блока?",
      "answer": "`synchronized` использует монитор объекта:\n- нестатический `synchronized`-метод/блок на `this` — монитор *экземпляра*,\n- `static synchronized` — монитор *объекта Class* (`SomeClass.class`), общий для всех экземпляров,\n- `synchronized(lockObj)` — монитор произвольного объекта.\n\nПри входе поток захватывает монитор, при выходе освобождает. Разблокировка даёт happens-before: изменения становятся видимы другим потокам, которые потом захватят тот же монитор."
    },
    {
      "question": "Как работает synchronized: метод vs блок?",
      "answer": "Функционально одинаково: и метод, и блок обеспечивают взаимное исключение и видимость.\n\nРазница в удобстве:\n- `synchronized`-метод блокирует на весь метод (проще, но часто «слишком широко»).\n- `synchronized`-блок можно сделать узким и можно выбрать отдельный объект-лок."
    },
    {
      "question": "Как реализовать потокобезопасный синглтон? Что выбрать: synchronized-метод или блок?",
      "answer": "Самые простые и надёжные варианты:\n- `enum`-singleton (рекомендуемый): потокобезопасно и защищено от сериализации/рефлексии.\n- holder-idiom: внутренний статический класс, лениво и потокобезопасно.\n\nЕсли нужно именно `synchronized`:\n- `synchronized`-метод `getInstance()` — просто, но может быть медленнее при частых вызовах.\n- double-checked locking: проверка `null`, `synchronized`, повторная проверка и `volatile` поле — быстрее на чтениях, но чуть сложнее."
    },
    {
      "question": "Как устроен ConcurrentHashMap и почему Hashtable считается неудачной?",
      "answer": "`Hashtable` синхронизирует почти все операции одним общим замком — из-за этого при конкуренции он плохо масштабируется.\n\n`ConcurrentHashMap` делает синхронизацию более «тонкой»: чтения в основном без блокировок, записи — через CAS и/или локи на уровне отдельных бакетов. Поэтому разные ключи можно обрабатывать параллельно.\n\nДополнительно: `ConcurrentHashMap` не хранит `null`, чтобы не путать `null` как значение и `null` как «ключа нет»."
    },
    {
      "question": "Какие атомарные классы в Java ты знаешь? Как они обеспечивают атомарность без блокировок (CAS)?",
      "answer": "Примеры: `AtomicInteger`, `AtomicLong`, `AtomicBoolean`, `AtomicReference`, `AtomicStampedReference`, `AtomicMarkableReference`, `AtomicIntegerArray`/`AtomicLongArray`, `LongAdder`, `LongAccumulator`.\n\nАтомарность обычно достигается через CAS (compare-and-swap): операция «если текущее значение равно ожидаемому — заменить на новое». В коде это выглядит как цикл: прочитал → посчитал новое → попытался CAS → если не вышло, повторил."
    },
    {
      "question": "Какие есть альтернативы synchronized (напр. Lock)?",
      "answer": "- `Lock`-интерфейсы: `ReentrantLock`, `ReadWriteLock`, `StampedLock`.\n- атомики: `Atomic*`, `LongAdder`.\n- конкурентные коллекции: `ConcurrentHashMap`, `ConcurrentLinkedQueue`, `BlockingQueue`.\n- синхронизаторы: `Semaphore`, `CountDownLatch`, `CyclicBarrier`, `Phaser`.\n- уменьшение shared state: иммутабельность, `ThreadLocal`, акторная/очередная модель."
    },
    {
      "question": "Какие ещё средства синхронизации, кроме synchronized, стоит знать?",
      "answer": "Из `java.util.concurrent` чаще всего:\n- `ReentrantLock`, `ReadWriteLock`, `Condition`\n- `Semaphore`\n- `CountDownLatch`, `CyclicBarrier`, `Phaser`\n- `Exchanger`\n- конкурентные коллекции (`BlockingQueue`, `ConcurrentHashMap`)\n- атомики (`Atomic*`, `LongAdder`)"
    },
    {
      "question": "Какие синхронизаторы из java.util.concurrent знаешь (Lock, Semaphore и др.)? Зачем ReentrantLock поверх synchronized?",
      "answer": "Синхронизаторы: `ReentrantLock`, `ReadWriteLock`, `StampedLock`, `Semaphore`, `CountDownLatch`, `CyclicBarrier`, `Phaser`, `Exchanger`, а также `BlockingQueue` как готовый механизм producer/consumer.\n\n`ReentrantLock` полезен поверх `synchronized`, когда нужны:\n- `tryLock()` (в т.ч. с таймаутом),\n- прерываемое ожидание (`lockInterruptibly()`),\n- справедливость (fair),\n- несколько независимых условий (`Condition`)."
    },
    {
      "question": "Какие состояния потока существуют в Java и как происходят переходы между ними?",
      "answer": "Состояния `Thread.State`: `NEW`, `RUNNABLE`, `BLOCKED`, `WAITING`, `TIMED_WAITING`, `TERMINATED`.\n\nПереходы (упрощённо):\n- `NEW` → `RUNNABLE` после `start()`.\n- `RUNNABLE` → `BLOCKED` при попытке войти в `synchronized`, если монитор занят.\n- `RUNNABLE` → `WAITING` при `wait()/join()` без таймаута.\n- `RUNNABLE` → `TIMED_WAITING` при `sleep()`, `wait(timeout)`, `join(timeout)`.\n- `RUNNABLE` → `TERMINATED` когда `run()` завершился."
    },
    {
      "question": "Какие способы создания/управления потоками поддерживаются в Java?",
      "answer": "Создание/выполнение:\n- `Thread` + `Runnable`.\n- `Callable` + `Future` через `ExecutorService`.\n- `CompletableFuture`/`CompletionStage` для композиции асинхронных задач.\n- `ForkJoinPool` и `RecursiveTask/RecursiveAction`.\n- виртуальные потоки (`Thread.ofVirtual()`, `Executors.newVirtualThreadPerTaskExecutor()`).\n\nУправление: `interrupt`, `join`, пулы (`shutdown`, `awaitTermination`), синхронизаторы (`Latch`, `Semaphore` и т.д.)."
    },
    {
      "question": "Какие типичные проблемы многопоточности (гонки данных, видимость, взаимные блокировки) встречаются?",
      "answer": "Частые проблемы:\n- race condition (гонка данных): результат зависит от порядка выполнения потоков.\n- visibility: один поток не видит обновления другого без happens-before.\n- deadlock: взаимная блокировка из-за циклического ожидания замков.\n- livelock: потоки активны, но прогресса нет (например, бесконечно «уступают» друг другу).\n- starvation: поток долго не получает ресурс.\n- контеншен и деградация производительности из-за чрезмерной синхронизации."
    },
    {
      "question": "Какие типы пулов потоков знаешь? Чем ForkJoinPool отличается (work-stealing)?",
      "answer": "Типы пулов: fixed, cached, single, scheduled, work-stealing, fork/join, а также виртуальные «per task».\n\n`ForkJoinPool` рассчитан на множество мелких задач и рекурсивное разбиение: каждый worker держит свою деку задач и при простое «ворует» задачи у других (work-stealing). Это снижает конкуренцию за общую очередь и хорошо подходит для CPU-bound параллелизма."
    },
    {
      "question": "Какие типы тредпулов умеет Executors?",
      "answer": "`Executors` предоставляет фабрики:\n- `newFixedThreadPool(n)`\n- `newCachedThreadPool()`\n- `newSingleThreadExecutor()`\n- `newScheduledThreadPool(n)` / `newSingleThreadScheduledExecutor()`\n- `newWorkStealingPool()` (на базе `ForkJoinPool`)\n\nВ современных версиях также актуален `Executors.newVirtualThreadPerTaskExecutor()`."
    },
    {
      "question": "Когда использовать synchronized, а когда высокоуровневые структуры (ConcurrentHashMap, BlockingQueue)?",
      "answer": "`synchronized` уместен для простых, коротких критических секций, когда логика своя и очень локальная (например, защитить пару полей и инвариант).\n\nВысокоуровневые структуры лучше, когда задача типовая:\n- общая мапа/набор — `ConcurrentHashMap`, `ConcurrentSkipListMap`,\n- producer/consumer — `BlockingQueue`,\n- счётчики — `Atomic*`/`LongAdder`,\n- координация — `CountDownLatch`, `Semaphore`.\n\nОни обычно безопаснее и лучше масштабируются."
    },
    {
      "question": "Кратко о модели памяти Java: happens-before, переупорядочивание, volatile.",
      "answer": "Java Memory Model (JMM) описывает, *когда* изменения одного потока обязаны стать видимыми другому и какие переупорядочивания допустимы компилятору/CPU.\n\nКлючевое понятие — happens-before: если A happens-before B, то эффекты A видимы в B.\n\n`volatile` создаёт happens-before между записью и последующим чтением этой переменной и ограничивает переупорядочивание вокруг неё. `synchronized` и `Lock` создают happens-before на границах захвата/освобождения замка."
    },
    {
      "question": "Модель памяти Java: что такое happens-before?",
      "answer": "Happens-before — это отношение порядка в JMM: если действие A happens-before действие B, то все записи, сделанные в A (и до A), гарантированно будут видимы в B.\n\nПримеры happens-before:\n- внутри одного потока: порядок инструкций программы,\n- `unlock` монитора happens-before последующий `lock` того же монитора,\n- запись в `volatile` happens-before чтение этой `volatile`,\n- `Thread.start()` happens-before началу `run()`,\n- завершение потока happens-before успешному `join()`."
    },
    {
      "question": "Почему без volatile/синхронизации возможны «странные» наблюдения значений между потоками?",
      "answer": "Без `volatile`/синхронизации между потоками нет happens-before, поэтому JVM и процессор могут:\n- держать значения в регистрах/кэшах и не сразу «публиковать» их в память,\n- переупорядочивать операции ради оптимизации.\n\nИз-за этого один поток может долго видеть старое значение, а также наблюдать состояния «в неожиданном порядке». Синхронизация и `volatile` ставят нужные барьеры видимости/порядка."
    },
    {
      "question": "Почему инкремент volatile int не атомарен?",
      "answer": "Потому что `x++` — это несколько шагов: прочитать `x`, прибавить 1, записать обратно.\n\n`volatile` гарантирует видимость чтения/записи, но не делает этот read-modify-write атомарным. Два потока могут прочитать одно и то же значение и записать один и тот же результат (потеря обновлений)."
    },
    {
      "question": "Почему контроллер с инкрементом обычного int не потокобезопасен? Как исправить?",
      "answer": "`counter++` над обычным `int` не атомарен, поэтому при параллельных запросах часть инкрементов потеряется.\n\nИсправления:\n- `AtomicInteger.incrementAndGet()` (или `LongAdder` при высокой конкуренции),\n- или `synchronized`/`Lock` вокруг инкремента,\n- или вообще избегать общего счётчика в памяти (например, писать в метрики/БД с учётом требований)."
    },
    {
      "question": "Почему volatile недостаточно вместо атомарных типов?",
      "answer": "`volatile` решает видимость и порядок, но не решает атомарность составных операций: «проверил → обновил», `++`, `putIfAbsent`-логика и т.п.\n\nАтомарные типы (`Atomic*`) умеют делать обновления на основе предыдущего значения *атомарно* (через CAS), поэтому подходят для счётчиков, состояний и неблокирующих алгоритмов."
    },
    {
      "question": "Типичные проблемы многопоточности: что такое race condition, deadlock, livelock, starvation?",
      "answer": "- Race condition: результат зависит от того, в каком порядке потоки выполнят операции над общими данными.\n- Deadlock: потоки навсегда ждут друг друга (циклическое ожидание ресурсов/локов).\n- Livelock: потоки не заблокированы, но постоянно «переигрывают» друг друга и не делают прогресса (частые повторы/уступки).\n- Starvation: поток слишком долго не получает ресурс (например, из-за несправедливого лока или постоянной занятости)."
    },
    {
      "question": "Чем отличаются подходы с tryLock/тайм-аутом и с упорядочиванием захвата блокировок?",
      "answer": "Lock ordering — профилактика: заранее выбираем строгий порядок захвата нескольких локов (например, по id), и тогда цикл ожидания не возникает.\n\n`tryLock`/таймаут — реактивный подход: если не удалось захватить лок быстро, откатываемся/освобождаем уже захваченное и пробуем позже. Это помогает избегать вечного ожидания, но требует продуманной логики повторов (backoff), иначе можно получить livelock."
    },
    {
      "question": "Что такое атомарность в многопоточности на практическом примере?",
      "answer": "Атомарность означает «как единое неделимое действие».\n\nПример: инкремент счётчика. Если операция атомарна, то два параллельных `increment()` всегда дадут +2. Если нет — возможна потеря обновлений.\n\nПрактически это достигается через `AtomicInteger.incrementAndGet()`, `LongAdder`, или блокировку (`synchronized/Lock`)."
    },
    {
      "question": "Что такое атомарность и консистентность в контексте многопоточности?",
      "answer": "Атомарность — операция выполняется как единое неделимое действие: другие потоки не видят «полу-состояние».\n\nКонсистентность (согласованность) — сохраняются инварианты данных. Например, при переводе денег важно, чтобы «списать» и «зачислить» происходило вместе; иначе можно временно нарушить инвариант (сумма балансов).\n\nЧтобы держать инварианты, часто нужно делать *группу* изменений атомарно."
    },
    {
      "question": "Что такое атомарность и консистентность в многопоточности?",
      "answer": "Атомарность: действие неделимо (либо выполнено полностью, либо не выполнено), для других потоков выглядит как один шаг.\n\nКонсистентность: система не попадает в противоречивые состояния (инварианты выполняются).\n\nВ многопоточности это обычно обеспечивается синхронизацией: `synchronized/Lock`, транзакциями, или корректными атомарными структурами данных."
    },
    {
      "question": "Что такое дедлок, как его диагностировать и как от него избавиться?",
      "answer": "Deadlock — ситуация, когда потоки навсегда ждут друг друга, потому что каждый удерживает ресурс и ждёт ресурс, удерживаемый другим (циклическое ожидание).\n\nДиагностика: thread dump (`jstack`, профайлеры) обычно показывает «Found one Java-level deadlock» и цепочку блокировок.\n\nИзбавляться: упорядочить захват локов, сократить область блокировки, избегать блокирующего I/O под локом, использовать `tryLock` с таймаутом, упростить модель синхронизации."
    },
    {
      "question": "Что такое deadlock и как его избежать?",
      "answer": "Deadlock — взаимная блокировка: потоки ждут друг друга из-за циклического ожидания замков/ресурсов.\n\nКак избежать:\n- всегда захватывать несколько локов в одном и том же порядке,\n- держать локи минимальное время,\n- не делать под локом блокирующие операции,\n- применять `tryLock`/таймаут,\n- использовать высокоуровневые структуры вместо «ручных» локов."
    },
    {
      "question": "Что такое deadlock и livelock? Примеры и как избегать.",
      "answer": "Deadlock: потоки *стоят* и ждут ресурсы друг друга. Пример: T1 держит lockA и ждёт lockB, T2 держит lockB и ждёт lockA.\n\nLivelock: потоки *не стоят*, но прогресса нет. Пример: оба потока используют `tryLock`, неудачно захватывают/освобождают и бесконечно повторяют.\n\nПрофилактика: для deadlock — lock ordering; для livelock — backoff (случайная задержка), ограничение числа повторов, справедливые локи."
    },
    {
      "question": "Что такое deadlock, livelock, starvation? Примеры и способы избежать.",
      "answer": "- Deadlock: циклическое ожидание локов (A→B и B→A). Избегаем порядком захвата локов и `tryLock`.\n- Livelock: активные повторы без прогресса (например, оба потока постоянно уступают). Избегаем backoff/лимитами повторов.\n- Starvation: поток долго не получает ресурс (например, писатель при постоянных читателях). Избегаем справедливыми локами, правильной политикой `ReadWriteLock`, ограничением конкуренции."
    },
    {
      "question": "Что такое livelock и как его избегать (fair locks, tryLock с таймаутом и др.)?",
      "answer": "Livelock — потоки «живые» (работают), но из-за взаимных уступок/повторов прогресса нет.\n\nКак избегать:\n- backoff: случайные/растущие задержки между попытками,\n- ограничение числа ретраев,\n- `tryLock(timeout)` вместо бесконечных попыток,\n- справедливые (fair) локи или очереди, если важно гарантировать прогресс."
    },
    {
      "question": "Примеры задач, где параллельное выполнение даёт проигрыш относительно последовательного. Почему?",
      "answer": "Параллелизм может быть медленнее, если:\n- задача маленькая и накладные расходы (разбиение, планирование, синхронизация) больше выгоды,\n- есть общий узкий ресурс: один замок, одна БД, один диск/сеть → контеншен,\n- много переключений контекста, перегрев CPU, плохая локальность кэша,\n- ограничения по памяти/пропускной способности (memory bandwidth).\n\nПример: `parallelStream()` на небольшой коллекции или при блокирующем I/O часто проигрывает."
    },
    {
      "question": "Объясните ForkJoinPool и стратегию work-stealing.",
      "answer": "`ForkJoinPool` — пул для задач, которые рекурсивно делятся на подзадачи (`fork`) и потом объединяют результат (`join`). Типичные задачи — CPU-bound divide-and-conquer.\n\nWork-stealing: у каждого worker есть своя двусторонняя очередь (deque). Он берёт задачи «с головы», а если у него нет работы — «ворует» задачи у других workers «с хвоста». Это снижает конкуренцию за общую очередь и повышает загрузку ядер."
    },
    {
      "question": "Пользовался ли атомиками? Зачем они, как работает CAS?",
      "answer": "Атомики используют для простых потокобезопасных операций без явных блокировок: счётчики, флаги, ссылки на состояние.\n\nCAS (compare-and-swap) — аппаратная/VM операция: «если текущее значение равно ожидаемому — заменить». На её основе строятся `incrementAndGet()`, `compareAndSet()` и т.д. Обычно это CAS-цикл: читаем значение → считаем новое → пытаемся заменить → если кто-то успел раньше, повторяем."
    },
    {
      "question": "Реализуй потокобезопасный счётчик с методами increment() и getValue() (через synchronized).",
      "answer": "Простейший вариант — синхронизировать доступ к полю:\n- `private int value;`\n- `public synchronized void increment() { value++; }`\n- `public synchronized int getValue() { return value; }`\n\nТак `synchronized` обеспечивает и взаимное исключение, и видимость изменений между потоками."
    },
    {
      "question": "Условия вызова wait/notify/notifyAll. В чём разница между notify и notifyAll? Пример использования.",
      "answer": "`wait/notify/notifyAll` можно вызывать только когда поток *держит монитор* объекта (внутри `synchronized(obj)`), иначе будет `IllegalMonitorStateException`.\n\n`wait()`:\n- освобождает монитор и переводит поток в ожидание.\n- просыпаться нужно в цикле `while (!condition) obj.wait();` из-за возможных spurious wakeups.\n\n`notify()` будит один случайный ожидающий поток, `notifyAll()` — будит всех (дальше они по очереди захватят монитор и проверят условие).\n\nПример: producer/consumer — производитель кладёт данные и делает `notifyAll()`, потребитель ждёт в `while(queue.isEmpty()) wait()`."
    },
    {
      "question": "Чем Callable отличается от Runnable?",
      "answer": "`Runnable` — задача без результата: `void run()`, не может бросать checked-исключения в сигнатуре.\n\n`Callable<T>` — задача с результатом: `T call() throws Exception`. Обычно используется с `ExecutorService.submit(...)`, который возвращает `Future<T>`."
    },
    {
      "question": "Чем ExecutorService лучше ручного управления потоками?",
      "answer": "`ExecutorService` лучше тем, что:\n- переиспользует потоки (меньше накладных расходов),\n- ограничивает параллелизм (защита ресурсов),\n- даёт очередь задач и управление жизненным циклом,\n- предоставляет `Future` для результата/отмены,\n- упрощает корректное завершение (`shutdown`).\n\nРучные `Thread` легко приводят к утечкам потоков, отсутствию лимитов и сложности поддержки."
    },
    {
      "question": "Чем lock-striping в ConcurrentHashMap лучше глобальной синхронизации?",
      "answer": "Lock striping — это разделение синхронизации на несколько независимых локов (например, по сегментам/бакетам), чтобы разные ключи могли обновляться параллельно.\n\nПо сравнению с глобальным локом (как в `Hashtable`) это снижает контеншен и увеличивает пропускную способность при высокой конкуренции."
    },
    {
      "question": "Чем Runnable отличается от Callable, как получить результат и почему Future.get() может «застопорить» поток?",
      "answer": "`Runnable` не возвращает результат; `Callable<T>` возвращает `T`.\n\nРезультат получают через `Future<T>`: `Future<T> f = executor.submit(callable); T v = f.get();`.\n\n`Future.get()` блокирует поток до готовности результата. Если вызвать его в потоке пула, который должен выполнить нужную задачу (или цепочку задач), можно «застопорить» пул и получить дедлок/просадку. Поэтому предпочитают таймауты или `CompletableFuture`-цепочки."
    },
    {
      "question": "Чем Runnable отличается от Callable?",
      "answer": "`Runnable` — `void run()`: нет результата.\n\n`Callable<T>` — `T call()`: есть результат и можно объявить `throws Exception`. В пулах обычно используют `Callable` вместе с `Future`."
    },
    {
      "question": "Чем Thread.start() отличается от Thread.run()?",
      "answer": "`start()` создаёт новый поток выполнения: JVM/ОС запускает новый thread, и уже в нём будет вызван `run()`.\n\n`run()` — это обычный метод. Если вызвать `run()` напрямую, код выполнится в текущем потоке, без параллелизма."
    },
    {
      "question": "Чем wait/notify/notifyAll отличаются? Когда применяются?",
      "answer": "`wait()` — отпускает монитор и переводит поток в ожидание до `notify/notifyAll` (или таймаута/прерывания).\n\n`notify()` будит один ожидающий поток, `notifyAll()` — всех.\n\nИспользуются для низкоуровневой координации по условию (condition queue). В реальном коде часто предпочтительнее `BlockingQueue`, `Lock`+`Condition`, `CountDownLatch` и другие примитивы из `java.util.concurrent`."
    },
    {
      "question": "Что даёт volatile с точки зрения happens-before и когда его уместно использовать?",
      "answer": "Запись в `volatile` переменную happens-before последующему чтению этой же переменной. Это значит: все записи, сделанные до `volatile`-записи, станут видимы потоку, который прочитал `volatile`.\n\nУместно использовать для:\n- флагов остановки (`volatile boolean stopped`),\n- публикации ссылок на иммутабельные объекты/снапшоты,\n- простых «последнее значение» без составных операций.\n\nНе подходит для `++` и сложных инвариантов."
    },
    {
      "question": "Что делает ключевое слово volatile и когда его имеет смысл применять/не применять при synchronized?",
      "answer": "`volatile` обеспечивает видимость и порядок для переменной, но не взаимное исключение.\n\nЕсли доступ к полю *всегда* происходит под `synchronized/Lock`, то `volatile` обычно не нужен: монитор уже даёт нужные happens-before.\n\nСмысл `volatile` появляется, когда чтения хочется делать без лока (например, флаг/состояние), но нужно гарантировать, что другие потоки увидят обновление."
    },
    {
      "question": "Что делает volatile? Когда его недостаточно?",
      "answer": "`volatile` гарантирует, что чтение увидит актуальную запись, и ограничивает переупорядочивание вокруг этой переменной.\n\nНедостаточно, когда нужна атомарность составных действий:\n- `x++`,\n- «проверил и установил»,\n- обновление нескольких полей как единого состояния.\n\nВ таких случаях нужны `Atomic*`/`LongAdder` или `synchronized/Lock`."
    },
    {
      "question": "Что означает принцип happens-before в Java Memory Model?",
      "answer": "Принцип happens-before задаёт правила видимости: если A happens-before B, то поток, выполняющий B, обязан увидеть результаты A.\n\nЭто то, на чём строится корректная публикация данных между потоками. Happens-before создают `volatile`, `synchronized`/`Lock`, `start/join`, а также некоторые операции в `java.util.concurrent`."
    },
    {
      "question": "Что означает happens-before для записи/чтения volatile и зачем это нужно?",
      "answer": "Для `volatile` правило такое: запись в `volatile` happens-before последующему чтению этой же переменной.\n\nЗачем: это даёт простой способ безопасно «публиковать» изменения. Например, поток A записал данные в обычные поля, затем записал `ready=true` (volatile). Поток B читает `ready`, и если увидел `true`, он гарантированно увидит и все данные, записанные до этого."
    },
    {
      "question": "Что произойдёт, если внешние вызовы «зависают», а вы используете общий ForkJoin common pool?",
      "answer": "`ForkJoinPool.commonPool()` — общий пул (его используют, например, `parallelStream()` и `CompletableFuture` по умолчанию).\n\nЕсли в нём запускать блокирующие/«зависающие» операции, рабочие потоки будут заняты ожиданием, и другие задачи в common pool начнут голодать: падает производительность, возможны «залипания» пайплайнов.\n\nРешение: выносить блокирующее I/O в отдельный `ExecutorService` или использовать виртуальные потоки; для fork/join есть `ManagedBlocker`, но проще не блокировать common pool."
    },
    {
      "question": "Что такое виртуальные потоки в Java и чем они соотносятся с реактивным программированием?",
      "answer": "Виртуальные потоки (Project Loom) — лёгкие потоки, которые JVM мультиплексирует на небольшое число «carrier» (платформенных) потоков. Они позволяют писать блокирующий код в стиле «как обычно», но запускать очень много одновременных задач.\n\nРеактивное программирование обычно строится на неблокирующем I/O и event loop, требуя «реактивного» стиля кода.\n\nВиртуальные потоки не заменяют реактивность, но часто позволяют решить те же задачи масштабирования для I/O проще: можно использовать привычные блокирующие API, если внешние ресурсы это выдерживают."
    },
    {
      "question": "Что такое монитор в Java? Можем ли мы им управлять напрямую?",
      "answer": "Монитор — «встроенный» механизм синхронизации, который есть у каждого объекта в Java. `synchronized` захватывает/освобождает монитор, а `wait/notify` работают с очередью ожидания монитора.\n\nНапрямую управлять монитором нельзя (нет API «создать монитор» или «освободить чужой монитор»): доступ только через `synchronized` и `wait/notify/notifyAll`."
    },
    {
      "question": "Что такое монитор объекта?",
      "answer": "У каждого объекта в Java есть монитор (intrinsic lock): он используется для `synchronized`.\n\nКогда поток входит в `synchronized(obj)`, он захватывает монитор `obj`; остальные потоки, пытающиеся захватить тот же монитор, будут ждать. Также у монитора есть «wait set» для `wait()`."
    },
    {
      "question": "Что такое монитор/synchronized и как работает взаимное исключение?",
      "answer": "`synchronized` обеспечивает взаимное исключение через монитор объекта: в критической секции одновременно может быть только один поток, захвативший монитор.\n\nПри выходе из `synchronized` монитор освобождается. Кроме взаимного исключения, это даёт и гарантию видимости: освобождение монитора happens-before последующему захвату того же монитора другим потоком."
    },
    {
      "question": "Что такое Callable, Future, CompletableFuture?",
      "answer": "`Callable<T>` — задача, которая возвращает результат (`T call()`).\n\n`Future<T>` — «ручка» на результат асинхронной задачи: можно проверить готовность, отменить, дождаться (`get`).\n\n`CompletableFuture<T>` — расширенный `Future` + `CompletionStage`: позволяет строить цепочки (`thenApply`, `thenCompose`), обрабатывать ошибки, комбинировать несколько задач (`allOf/anyOf`) и даже завершать вручную (`complete`)."
    },
    {
      "question": "Что такое fork/join и work-stealing?",
      "answer": "Fork/join — модель параллелизма, где задача рекурсивно делится на подзадачи (`fork`), а затем результаты объединяются (`join`).\n\nWork-stealing — стратегия планирования: у каждого worker своя очередь задач; если worker простаивает, он «ворует» задачи у других. Это помогает равномерно загрузить потоки без общей горячей очереди."
    },
    {
      "question": "Что такое Future и чем опасен вызов get()?",
      "answer": "`Future` представляет результат асинхронной операции: можно дождаться, отменить, проверить готовность.\n\n`get()` опасен тем, что блокирует поток. Если блокируемый поток — рабочий поток пула, это снижает пропускную способность и может привести к дедлоку (особенно если задачи внутри пула ждут друг друга). Обычно используют таймаут (`get(timeout)`), или `CompletableFuture`-композицию без блокировок."
    },
    {
      "question": "Что такое Java Memory Model? Объясни отношение happens-before и основные случаи, когда оно гарантируется.",
      "answer": "Java Memory Model (JMM) — правила, по которым потоки видят изменения друг друга и какие переупорядочивания допустимы.\n\nКлючевой механизм — happens-before: если A happens-before B, то результаты A видимы в B.\n\nОсновные гарантии happens-before:\n- порядок действий внутри одного потока,\n- `unlock`/`lock` одного и того же монитора (`synchronized`),\n- запись/чтение одной `volatile`,\n- `Thread.start()` → начало `run()`,\n- завершение потока → успешный `join()`,\n- многие операции из `java.util.concurrent` задают нужные барьеры (например, постановка/взятие из `BlockingQueue`)."
    },
    {
      "question": "Что такое volatile-переменные в Java? Какие гарантии JMM они дают?",
      "answer": "`volatile`-переменная — это переменная, чтения/записи которой имеют специальные гарантии JMM.\n\nГарантии:\n- видимость: чтение `volatile` видит последнюю запись этой `volatile` из другого потока,\n- порядок: запись в `volatile` happens-before последующему чтению,\n- атомарность одиночного чтения/записи для примитивов (в т.ч. `long/double` в современных Java).\n\nНо `volatile` не делает атомарными операции вида read-modify-write."
    },
    {
      "question": "Что такое volatile? На что распространяется гарантия видимости?",
      "answer": "`volatile` — модификатор, который обеспечивает видимость и упорядочивание для конкретной переменной.\n\nГарантия видимости распространяется на:\n- саму `volatile`-переменную,\n- и (через happens-before) на записи, которые были сделаны *до* записи в `volatile`, если другой поток прочитал эту `volatile`.\n\nНо `volatile` не «синхронизирует всё подряд»: инварианты из нескольких полей всё равно нужно защищать отдельно."
    },
    {
      "question": "Atomic* классы: как работают и когда их применять?",
      "answer": "`Atomic*` классы предоставляют атомарные операции без явных блокировок, обычно через CAS.\n\nКак работают: CAS-цикл — читаем текущее значение → вычисляем новое → `compareAndSet(expected, new)` → при конфликте повторяем.\n\nКогда применять:\n- счётчики, флаги, простое состояние,\n- неблокирующие алгоритмы,\n- вместо `synchronized`, когда нужна высокая конкуренция и маленькая критическая секция.\n\nПри сильном контеншене для счётчиков часто лучше `LongAdder`."
    },
    {
      "question": "Что делает планировщик потоков (thread scheduler) и имеет ли смысл менять приоритет потока (setPriority)?",
      "answer": "Планировщик потоков (в основном ОС) решает, какие потоки и когда получат CPU (кванты времени). JVM опирается на планировщик ОС.\n\n`Thread.setPriority(...)` — это лишь «подсказка» планировщику, которая по-разному работает на разных ОС и может игнорироваться. В серверном коде обычно не стоит полагаться на приоритеты; лучше решать задачи через правильный дизайн (пулы, очереди, лимиты) и мониторинг."
    },
    {
      "question": "Чем многопоточность в Java отличается от подхода с корутинами в Kotlin?",
      "answer": "В классической Java многопоточность — это потоки (platform threads): блокировки реально блокируют поток ОС.\n\nKotlin-корутины — это «лёгкие» кооперативные задачи: они могут *приостанавливаться* (suspend) без блокировки потока, и множество корутин выполняются на ограниченном числе потоков (dispatcher).\n\nВ Java появились виртуальные потоки, которые приближают модель к «лёгким задачам»: блокирующий код можно масштабировать лучше. Но корутины остаются языковой моделью с другими абстракциями (structured concurrency, suspending APIs)."
    }
  ]
}
