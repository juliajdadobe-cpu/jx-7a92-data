{
  "Архитектура / Микросервисы": [
    {
      "question": "Что делать при отказах зависимостей: ретраи, таймауты, circuit breaker?",
      "answer": "Базовые меры:\n- таймауты на все внешние вызовы (connect/read/overall),\n- ретраи только для безопасных ошибок (временные сети/5xx) + backoff + лимит,\n- circuit breaker, чтобы не «добивать» падающую зависимость,\n- fallback/деградация (кэш, упрощённый ответ),\n- bulkhead (изоляция ресурсов: отдельные пулы/лимиты),\n- наблюдаемость (метрики latency/error rate) и алерты.\n\nГлавное: не делать бесконечных ретраев и не держать транзакции/потоки во время ожидания."
    },
    {
      "question": "Что такое Circuit Breaker и зачем он нужен?",
      "answer": "Circuit Breaker — паттерн защиты от «падающих/медленных» зависимостей.\n\nОн переключается в состояние OPEN, если много ошибок/таймаутов, и временно перестаёт делать запросы к зависимости (быстро отдаёт ошибку/fallback). Затем пробует восстановление (HALF-OPEN).\n\nЗачем: чтобы не тратить ресурсы на заведомо провальные вызовы и не устроить каскадный отказ всей системы."
    },
    {
      "question": "Где и как деплоитесь: облако/свои ДЦ, виртуалки, Kubernetes?",
      "answer": "Типичные варианты:\n- облако (managed сервисы, проще масштабирование и наблюдаемость),\n- свои ДЦ/виртуалки (больше контроля, но больше операционных затрат),\n- Kubernetes (стандарт для контейнеров: rollout, autoscaling, service discovery).\n\nЧаще всего: Docker image → registry → деплой в Kubernetes (Deployment/Service/Ingress) через CI/CD."
    },
    {
      "question": "Где хранится контекст трассировки внутри JVM в MVC-приложении?",
      "answer": "В классическом MVC (thread-per-request) контекст трассировки обычно хранится в `ThreadLocal`:\n- MDC для логов,\n- контекст OpenTelemetry/Brave/Sleuth.\n\nОн живёт в рамках обработки запроса в текущем потоке и должен корректно прокидываться при асинхронности/передаче задач в пул."
    },
    {
      "question": "Где хранить медиа: БД или blob-storage (S3)? Как организовать presigned URL upload «в обход» бэкенда?",
      "answer": "Медиа (фото/видео) обычно хранят в blob-storage (S3/MinIO), а в БД — только метаданные и ссылки.\n\nПочему не БД: дорого по месту, сложнее масштабировать, тяжелее бэкапы.\n\nPresigned URL upload:\n1) клиент запрашивает у бэкенда presigned URL (проверив права),\n2) клиент загружает файл напрямую в S3 по этому URL,\n3) клиент/бэкенд фиксирует метаданные (ключ объекта, размер, checksum, content-type).\n\nТак бэкенд не прокачивает гигабайты трафика."
    },
    {
      "question": "Генерация ленты: fan-out on read vs fan-out on write — что выбираем и почему?",
      "answer": "- Fan-out on read: лента собирается при запросе (читаем посты авторов, сортируем). Плюсы: проще запись, меньше фоновой работы. Минусы: тяжёлое чтение при большом числе подписок.\n\n- Fan-out on write: при публикации поста раскладываем его в фиды подписчиков (feed workers). Плюсы: быстрые reads. Минусы: дорогие writes, «проблема селебрити».\n\nВыбор зависит от нагрузки: если чтение доминирует и важна быстрая лента — часто выбирают fan-out on write (часто гибрид)."
    },
    {
      "question": "Для какого региона проектируем (один регион или глобально)?",
      "answer": "Зависит от пользователей и требований.\n\nОдин регион проще: меньше задержки внутри, проще консистентность и операции.\n\nГлобально — сложнее: репликация данных, гео-DNS, multi-region актив-актив/актив-пассив, консистентность и latency trade-offs.\n\nОбычно начинают с одного региона и закладывают путь к расширению (CDN для медиа, реплики для чтения)."
    },
    {
      "question": "Зачем и когда выбирать микросервисную архитектуру вместо монолита?",
      "answer": "Выбирают, когда:\n- система и команда выросли, нужна независимая разработка/деплой частей,\n- разные компоненты имеют разные профили нагрузки и нужно масштабировать отдельно,\n- нужна изоляция отказов и автономность команд.\n\nНе стоит выбирать «сразу», если продукт небольшой: микросервисы увеличивают сложность (сеть, наблюдаемость, консистентность, деплой)."
    },
    {
      "question": "Зачем нужен распределённый трейсинг и как он помогает локализовать проблемы?",
      "answer": "Distributed tracing связывает запросы между сервисами через `traceId`/`spanId`.\n\nЭто помогает:\n- увидеть полный путь запроса (API → сервисы → БД/внешние вызовы),\n- понять, где именно время/ошибка,\n- анализировать p95/p99 и «хвосты».\n\nБез трассировки в микросервисах сложно понять, какой сервис реально «тормозит»."
    },
    {
      "question": "Идти ли воркерам напрямую в Follow DB или через Follow Service? Почему «shared DB» — антипаттерн?",
      "answer": "Обычно лучше ходить через Follow Service (его API/контракт), а не напрямую в его БД.\n\nПочему shared DB — антипаттерн:\n- сервисы становятся жёстко связаны схемой БД,\n- сложно менять схему без поломки других,\n- нарушается ownership данных и границы ответственности.\n\nЕсли нужна высокая производительность, используют репликацию данных/события (CDC, outbox) в отдельное хранилище, но всё равно избегают прямого доступа к чужой БД."
    },
    {
      "question": "Из чего строить feed DB (например, Redis Sorted Set: postId + createdAt/score)?",
      "answer": "Для быстрой ленты часто используют key-value/Redis:\n- `Sorted Set` на пользователя: score = время/ранжированный score, value = `postId`.\n- отдельное хранилище метаданных поста (Post DB) и медиа в S3.\n\nПлюсы Redis ZSET: быстрое получение top-N и cursor по score.\nМинусы: память, нужно TTL/trim, и продумывать консистентность/перестроение фида."
    },
    {
      "question": "Как боретесь с дубликатами сообщений при паттерне Outbox/идемпотентности?",
      "answer": "- делаем обработку идемпотентной: у события есть `eventId`, сохраняем «уже обработано» (уникальный индекс),\n- consumer может повторять безопасно (at-least-once),\n- в outbox используем уникальные ключи и аккуратные статусы.\n\nДубликаты — нормальны в распределённых системах, поэтому проектируют под at-least-once."
    },
    {
      "question": "Как бы вынёс «магические числа» и пороги в настройки? Как бы назвал конфиг-параметры?",
      "answer": "Вынес бы в конфигурацию приложения (properties/yaml/env) и/или в централизованный config (если есть).\n\nНейминг:\n- группировать по домену: `feed.maxPageSize`, `feed.precomputeWindowDays`,\n- явно указывать единицы: `timeouts.httpReadMs`, `kafka.retry.backoffMs`,\n- разделять лимиты: `rateLimit.requestsPerSecond`, `cache.ttlSeconds`.\n\nВажно: валидация конфигурации и разумные дефолты."
    },
    {
      "question": "Как встроить систему разных скидок (много правил, возможно комбинируемых) в текущий алгоритм?",
      "answer": "Обычно применяют rule engine/strategy:\n- описать скидку как правило (условие + эффект),\n- сделать набор независимых правил и механизм их композиции (приоритеты, суммирование, «максимальная скидка» и т.п.).\n\nВ коде: паттерны Strategy/Chain of Responsibility.\n\nВажно явно определить, как комбинируются скидки, и покрыть тестами, потому что это бизнес-критично."
    },
    {
      "question": "Как генерируете и храните ключ идемпотентности и где его проверяете?",
      "answer": "Ключ идемпотентности обычно генерирует клиент (UUID) или сервер (если есть стабильный бизнес-ключ).\n\nХранение:\n- в БД/Redis как запись «этот key уже обработан → результат/статус» с TTL.\n\nПроверка:\n- на входе в обработчик команды (HTTP endpoint/consumer),\n- атомарно: через уникальный индекс/insert-if-not-exists.\n\nВозвращаем тот же результат при повторе, а не выполняем действие второй раз."
    },
    {
      "question": "Как защитить слабый сервис от пиковых нагрузок (rate limiting, backpressure)?",
      "answer": "- Rate limiting (по пользователю/ключу/API),\n- очереди и асинхронная обработка (буферизация),\n- backpressure (ограничение выдачи/параллелизма),\n- кэширование,\n- деградация (отдавать упрощённый ответ),\n- circuit breaker/bulkhead,\n- autoscaling и правильные лимиты ресурсов.\n\nЦель — не допустить перегрузки и каскадных отказов."
    },
    {
      "question": "Как микросервисы помогают с масштабированием под пиковые нагрузки?",
      "answer": "Плюсы:\n- можно масштабировать только горячий сервис (например, feed),\n- изоляция ресурсов (пулы, лимиты),\n- разные технологии/хранилища под разные нагрузки,\n- отдельные деплои и оптимизации.\n\nНо это работает, если границы сервисов и контракты хорошо спроектированы."
    },
    {
      "question": "Как обеспечить транзакционную целостность между БД и сообщением в Kafka?",
      "answer": "Классическая проблема: нельзя «атомарно» сделать commit в БД и отправку в Kafka без распределённых транзакций.\n\nТиповое решение — Transactional Outbox:\n- в одной транзакции с бизнес-данными записываем событие в outbox-таблицу,\n- отдельный воркер читает outbox и публикует в Kafka,\n- после успешной публикации помечает outbox как отправленное.\n\nЭто даёт at-least-once доставку события и позволяет делать consumer’ов идемпотентными."
    },
    {
      "question": "Как обрабатывать лайки: идемпотентность (toggle), горячие счётчики, консистентность при высокой нагрузке?",
      "answer": "Лайк лучше делать идемпотентным:\n- `PUT /posts/{id}/likes/me` (поставить), `DELETE ...` (снять) — вместо «toggle».\n\nХранение:\n- таблица likes (userId, postId) с уникальным ключом,\n- счётчик лайков можно держать как денормализованный (в БД/Redis) и обновлять через события.\n\nПри высокой нагрузке: использовать кэш/шардинг/батчи, и понимать консистентность: счётчик может быть слегка «eventually consistent», но факт наличия лайка для пользователя должен быть точным."
    },
    {
      "question": "Как организован обработчик outbox-таблицы: шедулер, блокировки, удаление/пометки?",
      "answer": "Типовая схема:\n- воркер периодически выбирает пачку `NEW` событий (batch),\n- берёт их «в работу» безопасно (например, `SELECT ... FOR UPDATE SKIP LOCKED` или статус + optimistic update),\n- публикует в Kafka,\n- помечает как `SENT` (или сохраняет попытки/ошибку),\n- старые `SENT` чистит по TTL/архивирует.\n\nВажно: несколько воркеров должны работать без дублей (за счёт блокировок/статусов)."
    },
    {
      "question": "Как организовать outbox-читателей: батчи, идемпотентность, ретраи, backpressure?",
      "answer": "- Читать батчами (например, по 100–1000 записей),\n- ограничивать параллелизм публикации,\n- делать ретраи с backoff и лимитом,\n- при постоянной ошибке — парковать/помечать `FAILED` и алертить,\n- контролировать backpressure: не читать быстрее, чем можем отправить.\n\nИ всегда считать доставку at-least-once → consumer должен быть идемпотентным."
    },
    {
      "question": "Как передаётся traceId между сервисами?",
      "answer": "Обычно через HTTP headers (W3C Trace Context): `traceparent`/`tracestate`.\n\nВ логах traceId кладут в MDC.\n\nДля брокеров (Kafka) traceId можно передавать в headers сообщения.\n\nИнструменты (OpenTelemetry/Sleuth/Brave) делают это автоматически при правильной настройке."
    },
    {
      "question": "Как при откате транзакции откатить и запись в файле — как это можно реализовать?",
      "answer": "Нельзя «атомарно» откатить БД и файл обычной транзакцией.\n\nВарианты:\n- не писать файл до успешного commit (сначала в память/временный файл, потом rename после commit),\n- писать файл как отдельное событие после коммита (через outbox/event),\n- использовать двухфазный протокол/сагу: если БД откатилась — выполнить компенсирующее действие (удалить файл).\n\nЛучше проектировать так, чтобы файл был побочным эффектом после успешной транзакции."
    },
    {
      "question": "Как реализовать трассировку запросов между микросервисами (trace id/correlation id)?",
      "answer": "- Генерировать `traceId` на входе (или принимать от gateway).\n- Прокидывать его во все исходящие запросы (headers) и в сообщения (Kafka headers).\n- Добавить `traceId` в логи (MDC).\n- Использовать OpenTelemetry (SDK + exporters) и собирать трейсы в Jaeger/Tempo/Zipkin.\n\nТак можно собрать полный путь запроса и локализовать задержки."
    },
    {
      "question": "Как решаете проблему: в транзакции нужно отправить сообщение в Kafka, а транзакция откатывается?",
      "answer": "Если отправить сообщение напрямую в Kafka внутри транзакции, а потом сделать rollback — событие уже ушло, и система станет неконсистентной.\n\nРешение: Transactional Outbox.\n- в транзакции пишем данные + outbox запись,\n- публикацию делает воркер после коммита.\n\nАльтернатива: Kafka transactions + DB XA (обычно не используют из-за сложности). На практике — outbox."
    },
    {
      "question": "Как решать «проблему селебрити» при fan-out on write?",
      "answer": "Проблема: у «звезды» миллионы подписчиков → раскладка поста в миллионы фидов слишком дорогая.\n\nРешения (обычно гибрид):\n- для обычных пользователей — fan-out on write,\n- для селебрити — fan-out on read (подмешивать посты звезды при чтении),\n- отдельный топик/поток обработки и лимиты,\n- кеширование популярных постов,\n- хранить «селебрити-посты» отдельно и мерджить при чтении."
    },
    {
      "question": "Как уйти от хардкода скидок/порогов и дать возможность менять их без перезапуска приложения?",
      "answer": "Варианты:\n- вынести параметры в конфиг (properties/yaml/env) + dynamic reload (если есть),\n- хранить правила в БД и кэшировать (с админкой),\n- feature flags/config service.\n\nВажно: версионировать правила, валидировать, иметь аудит изменений и быстрый rollback."
    },
    {
      "question": "Как хранить отношения «follow» (модель follower/followee, двусторонность, индексация)?",
      "answer": "Модель обычно: таблица `follows(follower_id, followee_id, created_at)`.\n\nИндексы:\n- уникальный индекс на `(follower_id, followee_id)` (чтобы не было дублей),\n- индекс на `follower_id` (получить список подписок),\n- индекс на `followee_id` (получить подписчиков).\n\nЕсли нужны счётчики — держать денормализованные counters (eventually consistent) или считать агрегатами."
    },
    {
      "question": "Какие виды интеграций используете (REST/gRPC, брокеры, прямой доступ к БД, файлы) и когда какой выбрать?",
      "answer": "- REST: просто и универсально, хорошо для публичных API.\n- gRPC: эффективнее и строгие контракты, удобно для межсервисного синхронного взаимодействия.\n- брокеры (Kafka/RabbitMQ): асинхронность, буферизация, event-driven, лучше для слабосвязанных интеграций.\n- прямой доступ к чужой БД: обычно избегают (shared DB анти-паттерн).\n- файлы: для batch/выгрузок/интеграций, но сложнее в консистентности.\n\nВыбор зависит от требований по latency, консистентности, связности и нагрузке."
    },
    {
      "question": "Какие знаешь паттерны микросервисов, кроме SAGA?",
      "answer": "Примеры:\n- API Gateway,\n- Circuit Breaker, Bulkhead,\n- Retry/Timeout,\n- Service Discovery,\n- CQRS,\n- Event Sourcing,\n- Transactional Outbox,\n- Strangler Fig (миграция),\n- BFF (Backend for Frontend)."
    },
    {
      "question": "Какие проблемы/выгоды микросервисы решают помимо «single point of failure»?",
      "answer": "Выгоды:\n- независимый деплой и развитие частей,\n- отдельное масштабирование и оптимизация,\n- границы ответственности команд,\n- технологическая гибкость.\n\nПроблемы (цена):\n- распределённые транзакции/консистентность,\n- сеть и отказоустойчивость,\n- наблюдаемость,\n- больше DevOps и сложнее отладка.\n\nТо есть это trade-off, а не «всегда лучше»."
    },
    {
      "question": "Какие публичные API нужны (создать пост, получить пресайн-URL, подписаться/отписаться, поставить/снять лайк, получить ленту)?",
      "answer": "Минимальный набор:\n- создать пост (метаданные + ссылки на медиа),\n- получить presigned URL для загрузки медиа,\n- получить пост/профиль,\n- follow/unfollow,\n- like/unlike,\n- получить ленту (с пагинацией),\n- комментарии (если нужны).\n\nПлюс: auth (login/refresh), и админ/модерация при необходимости."
    },
    {
      "question": "Какие разновидности API Gateway бывают и чем они отличаются по задачам/клиентам?",
      "answer": "Варианты:\n- общий API Gateway для всех клиентов (единая точка входа),\n- BFF (Backend for Frontend) — отдельный gateway под web/mobile (оптимизирован под конкретный UI),\n- edge gateway vs internal gateway.\n\nЗадачи: аутентификация, rate limiting, routing, aggregation, TLS termination, observability.\n\nBFF полезен, когда web и mobile требуют разные формы данных."
    },
    {
      "question": "Какие функциональные требования у «микро-Инстаграма» (посты фото/видео, подписи, подписки, лайки, комментарии, лента)?",
      "answer": "Функционально:\n- регистрация/логин,\n- профиль пользователя,\n- публикация постов (фото/видео + caption),\n- хранение медиа,\n- подписки (follow/unfollow),\n- лайки (like/unlike),\n- комментарии,\n- лента (посты подписок) + пагинация,\n- поиск/рекомендации (опционально),\n- модерация/жалобы (опционально)."
    },
    {
      "question": "Какие SLA по генерации/отдаче ленты и как их мониторить?",
      "answer": "SLA/SLO обычно задают по:\n- latency выдачи ленты (p95/p99),\n- доступности (error rate),\n- свежести (staleness) — насколько быстро новый пост появляется у подписчиков.\n\nМониторинг:\n- метрики latency/error rate,\n- лаги очередей/воркеров,\n- распределённый трейсинг,\n- бизнес-метрики (время доставки поста в фид)."
    },
    {
      "question": "Какую пагинацию для ленты выбрать и почему курсорная лучше offset/limit? Какой ключ курсора?",
      "answer": "Для ленты обычно лучше cursor (keyset) pagination:\n- стабильнее при вставках новых постов,\n- быстрее на больших данных (нет большого `OFFSET`).\n\nКурсор обычно строят по сортировочному ключу:\n- `createdAt` + `postId` (как tie-breaker),\n- или `score` в Redis ZSET.\n\nЗапрос: «дай элементы после курсора» (`<` или `>` в зависимости от порядка)."
    },
    {
      "question": "Когда в системе имеет смысл применять паттерн SAGA?",
      "answer": "SAGA нужна, когда бизнес-операция включает несколько сервисов/БД и нельзя сделать одну ACID-транзакцию.\n\nПримеры: оформление заказа (заказ → оплата → резерв склада → доставка).\n\nSAGA позволяет согласовать состояние через последовательность шагов и компенсирующие действия при ошибках."
    },
    {
      "question": "Когда обновлять ленту при новом «follow»/«unfollow» (перестроение/дозаполнение фида)?",
      "answer": "Варианты:\n- при follow: дозаполнить фид последними N постами нового автора (background job) или подмешивать на чтении до прогрева.\n- при unfollow: можно сразу перестать показывать новые посты, а старые записи в кэше/фиде убрать лениво (по TTL) или асинхронной чисткой.\n\nЧасто делают компромисс: важна корректность «не показывать новые», а полный «перестрой фида» делают асинхронно."
    },
    {
      "question": "Когда отдаёте приоритет синхронному взаимодействию (REST), а когда асинхронному (Kafka)?",
      "answer": "Синхронно (REST/gRPC), когда:\n- нужен немедленный ответ пользователю,\n- операция короткая и зависимость надёжна,\n- важна простота.\n\nАсинхронно (Kafka), когда:\n- операция долгая/тяжёлая,\n- нужны буферизация и устойчивость к пикам,\n- интеграция между сервисами слабосвязана,\n- важен event-driven (события, обновление кэшей, фидов).\n\nЧасто делают гибрид: команда принимается синхронно, а «побочные эффекты» — асинхронно."
    },
    {
      "question": "Когда уместен паттерн Transactional Outbox и как его реализовать?",
      "answer": "Outbox уместен, когда нужно гарантировать: «если бизнес-изменение закоммитилось, событие будет опубликовано».\n\nРеализация:\n- таблица outbox (id, eventType, payload, status, createdAt, attempts),\n- в одной транзакции записываем бизнес-данные + outbox,\n- воркер читает `NEW`, публикует в Kafka, помечает `SENT`.\n\nЭто решает проблему атомарности БД+брокер без XA."
    },
    {
      "question": "Корректно ли открывать транзакцию и внутри неё ждать ответа внешнего сервиса? Почему это опасно?",
      "answer": "Обычно это плохая идея.\n\nПочему опасно:\n- держите DB-соединение и блокировки дольше, растёт contention,\n- при задержках/таймаутах внешнего сервиса транзакции «висят»,\n- повышается риск дедлоков и истощения пула соединений,\n- падает throughput.\n\nЛучше: разделять — короткая транзакция для БД, а внешние вызовы делать вне транзакции, либо через асинхронный процесс (outbox/saga)."
    },
    {
      "question": "Максимальные размеры медиа (фото/видео) и характер нагрузки (вечер/выходные пики)?",
      "answer": "Это нефункциональные требования, которые сильно влияют на архитектуру:\n- лимиты размера (например, фото до X МБ, видео до Y МБ),\n- пики (вечер/выходные) → нужен запас по пропускной способности и буферизация,\n- CDN для отдачи,\n- фоновые процессы (транскодирование видео),\n- квоты/лимиты и rate limiting.\n\nИх задают заранее, чтобы правильно выбрать хранилище, сеть и стратегию кэширования."
    },
    {
      "question": "Микросервисы vs монолит: ключевые плюсы и минусы?",
      "answer": "Монолит:\n+ проще разработка/деплой/отладка, одна транзакция, меньше сетевых проблем\n- сложно масштабировать части отдельно, сложнее независимые релизы при росте команды\n\nМикросервисы:\n+ независимые деплои, отдельное масштабирование, изоляция отказов\n- сложность: сеть, консистентность, observability, DevOps, тестирование интеграций\n\nОбычно начинают с монолита и выделяют сервисы по мере роста."
    },
    {
      "question": "Назови 3 паттерна для микросервисов и опиши один (например, API Gateway / Saga / Rate Limiter).",
      "answer": "Примеры паттернов: API Gateway, SAGA, Circuit Breaker.\n\nНапример, API Gateway:\n- единая точка входа,\n- аутентификация/авторизация, rate limiting,\n- маршрутизация к сервисам, агрегация ответов,\n- observability (логирование/трейсы).\n\nПлюс: разгружает сервисы от «edge» задач, но создаёт риск SPOF (решается HA)."
    },
    {
      "question": "Нефункциональные требования: порядок трафика (DAU/пиковый RPS), SLO/latency, доступность?",
      "answer": "Нефункциональные требования задают архитектуру:\n- DAU/пиковый RPS → сколько инстансов/партиций/ресурсов нужно,\n- SLO/latency (p95/p99) → кэш, ближе данные, асинхронность,\n- доступность (например, 99.9%) → репликация, отказоустойчивость, health checks.\n\nВажно заранее определить цели и мониторить их через метрики/алерты."
    },
    {
      "question": "Нужен ли API Gateway? Чем он отличается от просто L7-балансировщика? Риски единой точки отказа?",
      "answer": "API Gateway часто нужен, если есть много сервисов и общий набор «edge» задач: auth, rate limiting, routing, logging, CORS, aggregation.\n\nL7-балансировщик в основном распределяет трафик, а gateway добавляет бизнес-логику уровня API (policy).\n\nРиски: единая точка отказа и узкое место. Решают HA (несколько инстансов), горизонтальное масштабирование, простота конфигурации, лимиты."
    },
    {
      "question": "Нужно гарантировать «либо и сохранение заказа, и отправка уведомления, либо ничего». Как это реализовать?",
      "answer": "Нельзя сделать это идеально атомарно между БД и внешним уведомлением без распределённых транзакций.\n\nПрактичный подход:\n- сохранить заказ + outbox событие в одной транзакции,\n- после коммита воркер отправляет уведомление,\n- consumer/уведомляющий сервис идемпотентен.\n\nТо есть гарантируем: «если заказ сохранён, уведомление *будет отправлено* (at-least-once)», а не «отправилось строго в той же транзакции»."
    },
    {
      "question": "Нужно ли отделять Feed Service (отдача ленты) и Feed Workers (построение ленты)? Плюсы/минусы объединения.",
      "answer": "Разделение часто полезно:\n- Feed Workers могут быть CPU/IO-heavy и масштабироваться отдельно,\n- Feed Service должен быстро отвечать на чтение.\n\nПлюсы разделения: независимое масштабирование, изоляция, разные SLA.\nМинусы: больше инфраструктуры и сложнее отладка.\n\nДля MVP можно объединить, а при росте нагрузки — разделить."
    },
    {
      "question": "Ограничиваем ли количество подписок/подписчиков у пользователя?",
      "answer": "Это продуктово-архитектурное решение.\n\nОграничения помогают:\n- защитить систему от злоупотреблений/спама,\n- ограничить «взрыв» нагрузки (особенно на fan-out),\n- упростить хранение и обработку.\n\nЕсли ограничений нет, нужно быть готовым к селебрити-сценариям и закладывать гибридные стратегии."
    },
    {
      "question": "Отличие Kafka от классических брокеров (RabbitMQ) концептуально.",
      "answer": "Kafka — лог событий: хранит историю, consumer’ы читают по offset, можно replay, ориентирован на streaming.\n\nRabbitMQ — очередь сообщений: доставляет и обычно удаляет сообщения, сильнее про routing/exchanges, удобен для task queue.\n\nKafka чаще для event-driven и аналитики/стриминга, RabbitMQ — для очередей задач и сложной маршрутизации."
    },
    {
      "question": "Паттерн SAGA: для чего и какие варианты (оркестрация/хореография)?",
      "answer": "SAGA координирует распределённую бизнес-операцию между сервисами через последовательность шагов и компенсирующие действия.\n\nВарианты:\n- Оркестрация: есть центральный orchestrator, который командует шагами.\n- Хореография: сервисы реагируют на события друг друга без центрального координатора.\n\nОркестрация проще для контроля, хореография — менее связана, но сложнее отслеживать поток."
    },
    {
      "question": "План миграций/эволюции схемы (версионирование API, blue-green/canary, обратная совместимость)?",
      "answer": "Подход:\n- делать изменения обратно совместимыми (add-only поля, новые endpoints),\n- версионировать API (в URL/headers) при необходимости,\n- выкатывать через canary/blue-green,\n- использовать feature flags,\n- миграции БД: expand → migrate → contract (сначала добавить, потом переключить, потом убрать).\n\nЦель — обновления без простоя и без поломки старых клиентов."
    },
    {
      "question": "Планировщик раз в сутки на нескольких инстансах: как обеспечить единственный запуск (распределённая блокировка)?",
      "answer": "- Использовать распределённый lock (ShedLock) с хранением lock’ов в БД/Redis.\n- Альтернатива: Kubernetes `CronJob` (тогда задача запускается как отдельный job).\n- Или clustered scheduler.\n\nПлюс: делать задачу идемпотентной и логировать факт захвата lock."
    },
    {
      "question": "Поток данных при публикации: запись метаданных + событие в Kafka. Как обеспечить атомарность (Transactional Outbox)?",
      "answer": "Используют Transactional Outbox:\n- в одной транзакции: записать метаданные поста в Post DB и запись в outbox,\n- after-commit воркер читает outbox и публикует событие в Kafka,\n- помечает outbox как `SENT`.\n\nТак если транзакция откатилась — события не будет. Если коммитнулась — событие будет отправлено (at-least-once)."
    },
    {
      "question": "Почему финтех часто выбирает PostgreSQL для OLTP?",
      "answer": "Потому что Postgres:\n- сильные транзакции и консистентность (ACID),\n- богатый SQL и индексы,\n- зрелость, надёжность, репликация,\n- хорошая экосистема и инструменты.\n\nДля OLTP (много маленьких транзакций) это часто оптимальный баланс функциональности и надёжности."
    },
    {
      "question": "Разделять ли сервисы по паттерну нагрузки (post service / feed service)? Зачем это масштабированию?",
      "answer": "Да, часто имеет смысл.\n\nPost (создание/хранение постов) и Feed (выдача ленты) имеют разные нагрузки:\n- Post: меньше RPS, важна запись и сохранение медиа/метаданных,\n- Feed: много чтений, нужен быстрый ответ и кэш.\n\nРазделение позволяет независимо масштабировать и оптимизировать каждую часть."
    },
    {
      "question": "Стратегия хранения старых постов в фиде: TTL/trim/архив?",
      "answer": "Обычно в feed store держат ограниченное окно:\n- TTL/trim: хранить последние N постов или последние X дней.\n\nСтарые посты остаются в Post DB и доступны через профиль/поиск, но не обязательно хранятся в fast feed store.\n\nДля экономии памяти и стабильной производительности важно ограничивать размер фида."
    },
    {
      "question": "Требования по консистентности ленты: приемлема ли задержка появления поста у подписчиков?",
      "answer": "Это продуктовый выбор.\n\nЧасто допустима небольшая задержка (секунды/минуты) → можно строить фид асинхронно (eventual consistency).\n\nЕсли нужна почти мгновенная консистентность, система усложняется и дорожает (сильнее нагрузка на write path).\n\nОбычно выбирают «быстро и достаточно консистентно» + мониторинг staleness."
    },
    {
      "question": "Что делаете с производительностью outbox, если вставки/индексы становятся «узким местом»?",
      "answer": "Оптимизации:\n- партиционировать outbox по времени,\n- минимизировать индексы (только нужные),\n- батчить вставки/чтение,\n- чистить старые записи (TTL/архив),\n- выносить payload в компактный формат, хранить ссылку,\n- масштабировать воркеры и использовать `SKIP LOCKED`.\n\nВажно измерять: где узкое место — запись в outbox, чтение, публикация или БД."
    },
    {
      "question": "Что делать с записями в outbox после сохранения заказа? Как обрабатывать ошибки и ретраи?",
      "answer": "После успешной публикации:\n- пометить запись как `SENT` и/или сохранить время отправки,\n- периодически чистить/архивировать старые `SENT`.\n\nОшибки:\n- делать ретраи с backoff и лимитом попыток,\n- хранить `attempts`/`lastError`,\n- при постоянной ошибке переводить в `FAILED` и алертить,\n- обеспечивать идемпотентность публикации/consumer’ов (возможны повторы)."
    },
    {
      "question": "Что такое идемпотентность запросов и как её обеспечить?",
      "answer": "Идемпотентность: повторный одинаковый запрос даёт тот же эффект.\n\nКак обеспечить:\n- использовать идемпотентные методы (`PUT`/`DELETE`) по смыслу,\n- для `POST` — `Idempotency-Key` + хранение результата,\n- уникальные бизнес-ключи/unique constraints,\n- дедупликация по `requestId/eventId`.\n\nЭто важно при ретраях и сетевых сбоях."
    },
    {
      "question": "Что такое API Gateway и зачем он нужен?",
      "answer": "API Gateway — единая точка входа в систему.\n\nЗачем:\n- аутентификация/авторизация,\n- rate limiting, CORS, TLS termination,\n- маршрутизация к сервисам,\n- агрегация ответов, версионирование,\n- observability (логи/трейсы).\n\nОн упрощает клиентов и разгружает сервисы от «edge» задач."
    },
    {
      "question": "Что такое Kafka и зачем брокер по сравнению с прямым REST-взаимодействием? Какой паттерн архитектуры реализуется?",
      "answer": "Kafka — брокер/платформа для event streaming (топики, партиции, consumer groups).\n\nЗачем по сравнению с прямым REST:\n- асинхронность и буферизация (выдерживаем пики),\n- слабая связанность (producer не ждёт consumer’ов),\n- возможность нескольких потребителей и replay,\n- устойчивость к временным отказам.\n\nЭто реализует event-driven архитектуру (pub/sub, streaming)."
    },
    {
      "question": "Что хранить в метаданных поста (id автора, caption, ссылки на медиа, timestamps)?",
      "answer": "Обычно:\n- `postId`, `authorId`,\n- `caption`/описание,\n- ссылки/ключи на медиа (S3 object key/URL), тип медиа,\n- `createdAt`/`updatedAt`,\n- статус (draft/published/deleted),\n- счётчики (likes/comments) — либо как денормализованные поля, либо отдельно,\n- настройки приватности/видимости (если нужно).\n\nСами медиа — отдельно в blob storage."
    },
    {
      "question": "Эволюция REST-API: как добавить новое обязательное поле без поломки совместимости (версионирование)?",
      "answer": "Если добавить обязательное поле «в лоб», старые клиенты сломаются.\n\nСтратегия:\n- сначала добавить поле как *необязательное* (с default),\n- обновить сервер так, чтобы умел принимать/отдавать оба варианта,\n- обновить клиентов,\n- потом сделать поле обязательным (или выпустить новую версию API: `/v2`).\n\nТо есть: backward compatibility сначала, затем постепенное ужесточение."
    },
    {
      "question": "Key-Value vs реляционная БД для подписок? Нужны ли GSI/вторичные индексы (по follower и по followee)?",
      "answer": "Для подписок нужны быстрые запросы в обе стороны:\n- кого читает пользователь (по `followerId`),\n- кто подписан на пользователя (по `followeeId`).\n\nВ реляционной БД это решают индексами на обе колонки.\n\nВ key-value (например, DynamoDB) для второго направления часто нужны вторичные индексы (GSI) или отдельная «обратная» таблица.\n\nВыбор зависит от масштаба и требований: RDBMS проще и надёжнее для транзакций, KV может масштабироваться проще под огромные объёмы, но требует продуманной модели доступа."
    },
    {
      "question": "Что такое паттерн Сага и как он координирует распределённые транзакции?",
      "answer": "SAGA — это цепочка локальных транзакций в разных сервисах.\n\nКаждый шаг выполняет свою транзакцию и публикует событие/команду для следующего шага.\n\nЕсли что-то пошло не так, выполняются компенсирующие действия (compensating transactions) для отката бизнес-эффекта.\n\nТак достигается итоговая согласованность без 2PC."
    },
    {
      "question": "Что такое хореография в SAGA и чем отличается от оркестрации?",
      "answer": "Хореография: нет центрального координатора. Сервисы реагируют на события друг друга и сами решают, что делать дальше.\n\nОркестрация: есть orchestrator, который управляет шагами (посылает команды, ждёт ответы/события).\n\nХореография менее централизована, но сложнее контролировать и отлаживать поток. Оркестрация проще для контроля и мониторинга."
    }
  ]
}
