{
  "Kafka / Messaging": [
    {
      "question": "Семантики доставки: at-most/at-least/exactly-once — как достигаются?",
      "answer": "- At-most-once: сообщение доставляется 0 или 1 раз (возможна потеря). Достигается, если коммитить offset *до* обработки или не делать ретраи при ошибках.\n\n- At-least-once: сообщение доставляется 1 или больше раз (возможны дубликаты). Достигается, если сначала обработать, а потом коммитить offset. При падении после обработки, но до коммита — сообщение придёт снова.\n\n- Exactly-once: «эффект ровно один раз» для связки producer+broker+consumer. В Kafka это достигается через idempotent producer + транзакции (EOS) и/или через идемпотентную обработку у consumer (уникальные ключи, outbox, дедупликация)."
    },
    {
      "question": "Что делать с «плохими» сообщениями: ретраи, DLT/DLQ, «парковка»?",
      "answer": "Стратегия обычно такая:\n- Разделить ошибки на временные (retryable) и постоянные (non-retryable).\n- Retry: несколько попыток с backoff (желательно с ограничением).\n- Если не получилось — отправить в DLT/DLQ (dead-letter topic/queue) с причиной и метаданными.\n- «Парковка»: отдельный поток/хранилище для ручного разбора и повторной обработки после фикса.\n\nВажно не блокировать основную партицию бесконечными ретраями и иметь мониторинг по DLT."
    },
    {
      "question": "В чём принципиальная разница между Kafka и RabbitMQ и когда что использовать?",
      "answer": "Kafka — распределённый лог (commit log): сообщения хранятся в топиках, consumer’ы читают по offset, можно перечитывать, высокая пропускная способность, партиции.\n\nRabbitMQ — брокер очередей: сообщения обычно «доставляются и удаляются», гибкая маршрутизация (exchanges), удобен для классических очередей задач.\n\nКогда:\n- Kafka: event streaming, аудит событий, высокая нагрузка, много потребителей, возможность replay.\n- RabbitMQ: task queue, сложная маршрутизация, RPC через очереди, когда важнее «доставка задач», чем хранение истории."
    },
    {
      "question": "Гарантии доставки в Kafka: at-most-once, at-least-once, exactly-once — отличия?",
      "answer": "- At-most-once: быстрее, но возможна потеря сообщений.\n- At-least-once: сообщений не теряем, но возможны дубликаты (нужна идемпотентность).\n- Exactly-once: цель — «эффект ровно один раз» (без потерь и без дублей) в рамках транзакционной модели Kafka, но требует правильной настройки producer/consumer и обычно всё равно предполагает идемпотентную бизнес-логику."
    },
    {
      "question": "Где и как обрабатывать ошибки десериализации, таймауты и ребаланс в Kafka?",
      "answer": "- Ошибки десериализации: лучше ловить как можно ближе к consumer’у. В Spring Kafka обычно используют `ErrorHandlingDeserializer` и error handler, чтобы отправлять сообщение в DLT и не «ронять» весь listener.\n\n- Таймауты: задавать таймауты на внешние вызовы внутри обработки, чтобы не зависать и не держать партицию. При необходимости — ретраи и DLT.\n\n- Ребаланс: происходит при смене состава consumer group или таймаутах. Важно корректно коммитить offsets, обрабатывать `ConsumerRebalanceListener` (если нужно), и делать обработку идемпотентной (потому что сообщения могут быть переобработаны)."
    },
    {
      "question": "Где хранятся оффсеты и кто их коммитит?",
      "answer": "Offsets хранятся в Kafka в специальном топике `__consumer_offsets`.\n\nКоммитит offsets consumer (клиент) — автоматически (auto-commit) или вручную (manual commit) в зависимости от настройки.\n\nПрактически безопаснее контролировать момент коммита: коммитить после успешной обработки, чтобы понимать семантику at-least-once."
    },
    {
      "question": "Для чего используется Kafka? Базовые понятия: топики, партиции, consumer group?",
      "answer": "Kafka используют для потоковой передачи событий: event streaming, интеграции микросервисов, сбор логов/метрик, построение пайплайнов.\n\nБазовые понятия:\n- Topic — логическая «лента» сообщений.\n- Partition — часть топика (упорядочена внутри себя), единица параллелизма.\n- Consumer group — группа потребителей: каждый partition читается максимум одним consumer в группе, чтобы распределить нагрузку.\n- Offset — позиция consumer’а в партиции."
    },
    {
      "question": "Зачем ключ сообщения и как он влияет на порядок?",
      "answer": "Ключ сообщения (`key`) влияет на выбор партиции: обычно партиция выбирается как `hash(key) % partitions`.\n\nЭто важно, потому что порядок в Kafka гарантируется *внутри одной партиции*. Если все события одного агрегата/пользователя идут с одним key, они попадут в одну партицию и будут читаться в порядке записи.\n\nБез key сообщения распределяются более случайно, и порядок по конкретному пользователю/заказу не гарантируется."
    },
    {
      "question": "Зачем ключ у сообщения (гарантия порядка внутри ключа)? Что будет без ключа?",
      "answer": "Ключ нужен, чтобы «приклеить» связанные события к одной партиции и сохранить порядок обработки для этого ключа.\n\nБез ключа producer обычно распределяет сообщения по партициям round-robin, и события одного пользователя/заказа могут попасть в разные партиции → порядок между ними потеряется."
    },
    {
      "question": "Как бороться с дубликатами сообщений у потребителя (идемпотентность/ключи)?",
      "answer": "В Kafka при at-least-once дубликаты возможны, поэтому consumer должен быть идемпотентным.\n\nСпособы:\n- хранить уникальный `eventId` и делать дедупликацию (таблица processed_events с уникальным индексом),\n- делать операции идемпотентными по бизнес-ключу (например, upsert),\n- использовать transactional outbox/inbox паттерны,\n- для producer: idempotent producer уменьшает дубликаты при ретраях отправки, но не решает всё на стороне consumer."
    },
    {
      "question": "Как выбираете ключ партиционирования сообщения в Kafka?",
      "answer": "Выбираю key так, чтобы:\n- сохранить нужный порядок (все события одного агрегата/пользователя в одну партицию),\n- равномерно распределить нагрузку (key должен быть достаточно разнообразным).\n\nЧастые варианты: `userId`, `orderId`, `accountId`.\n\nЕсли key слишком «горячий» (один пользователь генерит 90% событий), получится hot partition — тогда нужно менять стратегию (доп. шардирование, другой ключ, отдельный топик)."
    },
    {
      "question": "Как выбираете количество партиций в Kafka-топике и по какому принципу масштабируете их число?",
      "answer": "Партиции — это единица параллелизма: в одной consumer group максимум `N partitions` consumers могут активно читать.\n\nВыбираю количество партиций, исходя из:\n- целевого throughput и времени обработки,\n- числа consumer-инстансов (и запаса на масштабирование),\n- распределения по ключам (чтобы не было hot partitions),\n- нагрузки на кластер (много партиций = больше файлов/метаданных и overhead).\n\nМасштабирование:\n- обычно сначала масштабируют consumers (до числа partitions),\n- если упёрлись — увеличивают partitions, но помнят: это влияет на распределение `key -> partition` и может изменить «шардинг»."
    },
    {
      "question": "Как выбираете количество партиций относительно числа инстансов/консюмеров?",
      "answer": "В одной consumer group:\n- один partition может читать только один consumer,\n- если consumers больше, чем partitions — часть consumers будет простаивать,\n- если partitions больше, чем consumers — один consumer будет читать несколько partitions.\n\nОбычно partitions выбирают так, чтобы можно было масштабироваться по горизонтали и иметь запас, но без безумного количества."
    },
    {
      "question": "Как гарантировать «доставится точно» и когда/как чистить успешные записи?",
      "answer": "«Точно доставится» на практике означает: не потерять и корректно обработать.\n\nОбычно используют:\n- at-least-once + идемпотентная обработка (самый популярный подход),\n- DLT для проблемных сообщений,\n- сохранение статуса обработки в БД.\n\nЕсли храните таблицу дедупликации/processed events, её чистят по TTL или батчами, когда уверены, что повторная доставка старых событий уже не актуальна (например, через N дней)."
    },
    {
      "question": "Как добиться «ровно один раз» у потребителя и чем это отличается от «по меньшей мере один раз»?",
      "answer": "At-least-once: сообщение может прийти повторно → нужно уметь пережить дубль.\n\n«Exactly-once» у consumer’а обычно достигают не магией, а идемпотентностью:\n- уникальный `eventId` + запись в БД «обработано» в одной транзакции с бизнес-изменениями (inbox pattern),\n- либо Kafka transactions + read-process-write в Kafka (EOS) при обработке между топиками.\n\nРазница: at-least-once проще, но требует дедупликации; exactly-once сложнее и имеет ограничения."
    },
    {
      "question": "Как достигается гарантия порядка сообщений в Kafka?",
      "answer": "Kafka гарантирует порядок *только внутри одной партиции*.\n\nЧтобы сохранить порядок для конкретного ключа (пользователь/заказ), нужно:\n- отправлять все связанные сообщения с одинаковым `key`,\n- и читать их в одной consumer group (один consumer на партицию).\n\nМежду разными партициями общий порядок не гарантируется."
    },
    {
      "question": "Как масштабировать воркеры при росте Kafka-лага? Как шардировать по пользователям/партициям?",
      "answer": "Лаг растёт, когда потребители не успевают обрабатывать.\n\nМасштабирование:\n- увеличить число consumer-инстансов в группе (до количества partitions),\n- оптимизировать обработку (батчи, меньше внешних вызовов, параллелизм внутри consumer’а аккуратно),\n- при необходимости увеличить partitions (дорого и меняет распределение).\n\nШардирование по пользователям обычно делают через key = `userId`, чтобы события одного пользователя были в одной партиции."
    },
    {
      "question": "Как мониторите/тюните производительность обработки (RPS, задержки) при росте числа партиций?",
      "answer": "Мониторю:\n- consumer lag (по партициям),\n- время обработки сообщения, p95/p99,\n- throughput (msgs/sec),\n- rebalance частоту,\n- ошибки/DLT,\n- загрузку CPU/GC, сетевые метрики.\n\nТюнинг:\n- настройки consumer (fetch sizes, max.poll.records),\n- батч-обработка,\n- таймауты и ограничение внешних вызовов,\n- правильное число partitions и инстансов,\n- backpressure/ограничение параллелизма."
    },
    {
      "question": "Как обеспечиваете порядок обработки событий одного агрегата/идентификатора в Kafka?",
      "answer": "- выбираю `key = aggregateId` (например, `orderId`), чтобы события попадали в одну партицию,\n- обрабатываю последовательно внутри партиции (один consumer читает партицию),\n- избегаю параллельной обработки сообщений одной партиции, если важен строгий порядок.\n\nЕсли нужен порядок и при увеличении partitions — заранее проектируют шардирование и не меняют ключевую стратегию без миграционного плана."
    },
    {
      "question": "Как отложить запуск @KafkaListener при старте приложения?",
      "answer": "В Spring Kafka можно:\n- отключить автозапуск контейнеров (`autoStartup = \"false\"` у listener container) и стартовать вручную через `KafkaListenerEndpointRegistry`,\n- или использовать `@EventListener(ApplicationReadyEvent.class)` и там включать listeners,\n- или управлять через property и профили.\n\nЭто полезно, когда нужно дождаться прогрева/миграций/готовности зависимостей."
    },
    {
      "question": "Как распределяются партиции при 10 partitions и 11 consumers? При 2 consumers и 10 partitions?",
      "answer": "В одной consumer group:\n- 10 partitions и 11 consumers: 10 consumers получат по одной партиции, 1 consumer останется без партиций (idle).\n- 2 consumers и 10 partitions: партиции распределятся примерно поровну (например, 5 и 5), каждый consumer будет читать несколько партиций.\n\nРаспределение делает coordinator при ребалансе."
    },
    {
      "question": "Как удаляются сообщения из Kafka? Что такое сегменты и retention?",
      "answer": "В Kafka сообщения не удаляются «по одному» при чтении. Топик — это лог.\n\nУдаление происходит по политике retention:\n- по времени (retention.ms) и/или по размеру (retention.bytes).\n\nСегменты — это файлы лога внутри партиции. Когда сегмент выходит за retention, он удаляется целиком.\n\nТакже есть log compaction (по ключу): оставляет последние значения для каждого key."
    },
    {
      "question": "Какие семантики доставки сообщений вы знаете (at-most-once, at-least-once, exactly-once) и как их достичь?",
      "answer": "- at-most-once: коммит до обработки или «best effort» без ретраев.\n- at-least-once: обработка → коммит; возможны дубликаты.\n- exactly-once: Kafka transactions + idempotent producer (для read-process-write), и/или идемпотентный consumer с дедупликацией на стороне БД.\n\nНа практике чаще выбирают at-least-once + идемпотентность."
    },
    {
      "question": "Кто обеспечивает семантику доставки — брокер или консьюмер?",
      "answer": "Это совместная ответственность.\n\nKafka-брокер хранит сообщения и offsets, поддерживает транзакции/идемпотентный producer.\n\nНо реальная семантика «насколько корректно обработано» зависит от consumer’а:\n- когда он коммитит offset,\n- идемпотентна ли бизнес-обработка,\n- как обрабатываются ошибки/ретраи.\n\nПоэтому «ровно один раз» почти всегда требует логики на стороне приложения."
    },
    {
      "question": "Куда в Kafka пишутся сообщения (partition)? Как выбирается партиция (key → hash)?",
      "answer": "Сообщения пишутся в конкретную партицию топика.\n\nВыбор партиции:\n- если есть `key`, обычно используется `hash(key) % partitions` (детали зависят от partitioner’а),\n- если key нет — часто round-robin по партициям.\n\nПорядок гарантируется внутри выбранной партиции."
    },
    {
      "question": "Можно ли гарантировать порядок между разными партициями? Какими приёмами?",
      "answer": "Строгий порядок между разными партициями Kafka не гарантирует.\n\nЕсли нужен общий порядок, варианты:\n- использовать одну партицию (ограничивает параллелизм),\n- или вводить упорядочивание на уровне приложения: timestamps/sequence numbers и сборка/сортировка (сложно и дорого).\n\nОбычно проектируют так, чтобы порядок был нужен только внутри одного ключа (и тогда key → одна партиция)."
    },
    {
      "question": "Один топик/4 партиции/1 consumer: на сколько партиций подпишется? Что будет при добавлении второго?",
      "answer": "Если в группе 1 consumer и 4 partitions — он читает все 4 партиции.\n\nЕсли добавить второго consumer в ту же группу — произойдёт rebalance, и партиции распределятся между ними (примерно 2 и 2).\n\nПри ребалансе чтение временно приостанавливается и перераспределяются ownership’ы."
    },
    {
      "question": "Основные сущности Kafka: topic, partition, offset, consumer group.",
      "answer": "- Topic: логическая лента сообщений.\n- Partition: упорядоченная часть топика (единица параллелизма).\n- Offset: позиция сообщения в партиции для конкретного consumer’а.\n- Consumer group: группа потребителей, совместно читающих топик; внутри группы один partition читается максимум одним consumer."
    },
    {
      "question": "Что произойдёт, если у топика 5 партиций, а консьюмеров в группе 10?",
      "answer": "Максимум 5 consumers будут активно читать (по одному на партицию). Остальные 5 будут простаивать без назначенных партиций.\n\nПараллелизм чтения ограничен числом partitions."
    },
    {
      "question": "Что такое ключ партиционирования и как он влияет на порядок?",
      "answer": "Ключ партиционирования — это `key` сообщения, который используется для выбора партиции.\n\nЕсли ключ постоянен для одного агрегата (например, `orderId`), то все его события попадут в одну партицию → сохраняется порядок обработки для этого ключа.\n\nЕсли key нет или он «скачет», события разъедутся по партициям и порядок для агрегата потеряется."
    },
    {
      "question": "Что такое ребаланс и когда он происходит?",
      "answer": "Ребаланс — перераспределение партиций между consumers в одной group.\n\nПроисходит, когда:\n- consumer добавился/вышел,\n- consumer «умер» или превысил таймаут (не делал poll),\n- изменилось число партиций,\n- изменились подписки.\n\nВо время ребаланса обработка может временно остановиться, поэтому важно делать обработку быстрой и правильно настраивать таймауты."
    },
    {
      "question": "Что такое ребалансировка consumer group и к чему она приводит?",
      "answer": "Это процесс назначения партиций consumers.\n\nК чему приводит:\n- временная пауза в обработке,\n- возможные повторные обработки (если offsets не успели закоммититься),\n- перераспределение нагрузки.\n\nЧастые ребалансы — плохой симптом: обычно лечат временем обработки, настройками `max.poll.interval.ms`, heartbeat и стабильностью consumers."
    },
    {
      "question": "Что такое consumer group и почему она важна для распределения чтения без дублей?",
      "answer": "Consumer group — это набор consumers с одним `group.id`.\n\nВнутри группы каждый partition назначается максимум одному consumer → сообщения из partition обрабатываются без параллельного дубля в рамках группы.\n\nЭто ключевой механизм масштабирования: добавляя consumers, вы распределяете партиции между ними.\n\nВажно: разные группы читают независимо — это нормально, если вам нужно несколько разных обработчиков."
    },
    {
      "question": "Kafka: как гарантировать, что сообщения одного пользователя читает один consumer?",
      "answer": "Нужно:\n- публиковать сообщения с `key = userId`, чтобы они всегда попадали в одну партицию,\n- использовать одну consumer group (внутри группы один consumer читает партицию).\n\nТогда все события этого userId будут обрабатываться одним consumer’ом последовательно (пока число партиций не меняют без миграционного плана)."
    }
  ]
}
